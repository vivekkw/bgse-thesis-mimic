{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEWEST FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier # Load k-NN from sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score, confusion_matrix\n",
    "\n",
    "import collections\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "import unittest\n",
    "\n",
    "from mesa.time import RandomActivation, SimultaneousActivation, BaseScheduler\n",
    "from mesa.datacollection import DataCollector\n",
    "from mesa import Model, Agent\n",
    "from mesa.batchrunner import BatchRunner\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc(y, y_pred_probabilities, class_labels, column =1, plot = True):\n",
    "    fpr, tpr, _ = roc_curve(y == column, y_pred_probabilities[:,column])\n",
    "    roc_auc = roc_auc_score(y_true=y, y_score=y_pred_probabilities[:,1])\n",
    "    print (\"AUC: \", roc_auc)\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and merging data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_scores_df = pd.read_csv('severity_scores_df.csv')\n",
    "severity_scores_df=severity_scores_df.drop_duplicates(subset='subject_id',keep='first').sort_values(by='subject_id')\n",
    "\n",
    "# Removing redundant columns Subject_ID and HADM_ID\n",
    "severity_scores_df = severity_scores_df.drop(['subject_id','hadm_id','icustay_expire_flag','ICUSTAY_AGE_GROUP',\n",
    "                                              'OASIS', 'OASIS_PROB','age_score','preiculos_score', 'gcs_score',\n",
    "                                                'heartrate_score', 'meanbp_score',\n",
    "                                               'resprate_score', 'temp_score',\n",
    "                                               'UrineOutput_score', 'mechvent_score',\n",
    "                                               'electivesurgery_score', 'SAPS', 'resp_score', 'vent_score',\n",
    "                                               'hematocrit_score', 'glucose_score', 'SAPSII', 'SAPSII_PROB',\n",
    "                                               'PaO2FiO2_score', 'bilirubin_score', 'comorbidity_score',\n",
    "                                               'admissiontype_score', 'SOFA','INTIME','age'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df2 = pd.read_csv(\"main_df2.csv\")\n",
    "\n",
    "# Remove duplicate 'DEATHRATE_INT_CAT__' columns\n",
    "main_df2 = main_df2.drop(['DEATHRATE_INT_CAT__1.0_x', 'DEATHRATE_INT_CAT__2.0_x'],axis=1)\n",
    "main_df2 = main_df2.rename({'DEATHRATE_INT_CAT__1.0_y':'DEATHRATE_INT_CAT__1.0',\n",
    "                            'DEATHRATE_INT_CAT__2.0_y':'DEATHRATE_INT_CAT__2.0'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main_df2.merge(severity_scores_df, how='left', left_on = 'ICUSTAY_ID' ,right_on='icustay_id')\n",
    "\n",
    "vitals_df = pd.read_csv(\"vitals_df.csv\")\n",
    "df = df.merge(vitals_df, how='inner', on='icustay_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Encoding\n",
    "\n",
    "diagnosis_encoder = BinaryEncoder()\n",
    "diagnosis_binary = diagnosis_encoder.fit_transform(df['ICD9_CODE'].astype(str))\n",
    "\n",
    "# Create dummies for Gender\n",
    "gender_df =pd.get_dummies(df ['GENDER'],prefix='gender_', drop_first=True)\n",
    "\n",
    "# Create dummies for Age Group\n",
    "age_group_df =pd.get_dummies(df ['ICUSTAY_AGE_GROUP'], prefix='age_group_', drop_first=True)\n",
    "\n",
    "# Create dummies for Admission Type\n",
    "admtype_df =pd.get_dummies(df ['ADMISSION_TYPE'],prefix='ADMISSION_TYPE_', drop_first=True)\n",
    "\n",
    "# Create dummies for Insurance Type\n",
    "instype_df =pd.get_dummies(df ['INSURANCE'],prefix='INSURANCE_TYPE_', drop_first=True)\n",
    "\n",
    "# Creat dummies for car_unit\n",
    "care_unit = pd.get_dummies(df ['CURR_CAREUNIT'], prefix='careunit_', drop_first=True)\n",
    "\n",
    "# Merge all encoded variables\n",
    "df2 = pd.concat([df,gender_df,age_group_df,admtype_df,instype_df,care_unit], axis=1) #, diagnosis_binary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformatting Time Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with time variables\n",
    "\n",
    "df2['OUTTIME'] = pd.to_datetime(df2['OUTTIME'],format='%Y-%m-%d')\n",
    "df2['INTIME'] = pd.to_datetime(df2['INTIME'],format='%Y-%m-%d')\n",
    "# df2['DOB'] = pd.to_datetime(df2['DOB'],format='%Y-%m-%d')\n",
    "\n",
    "# Shift timescale\n",
    "df2['INTIME_ACTUAL']= df2['INTIME']+ pd.to_timedelta(df2['DIFF'],unit='D')\n",
    "df2['OUTTIME_ACTUAL']= df2['OUTTIME']+ pd.to_timedelta(df2['DIFF'],unit='D')\n",
    "# df2['DOB_ACTUAL']= df2['DOB']+ pd.to_timedelta(df2['DIFF'],unit='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.drop(['icustay_id', 'hospital_expire_flag',\n",
    "               'ICUSTAY_ID', 'SUBJECT_ID', 'HADM_ID', 'INTIME', 'OUTTIME', 'DIFF',\n",
    "               'LAST_WARDID', 'GENDER','DOB', 'ICD9_CODE', 'SHORT_TITLE',\n",
    "               'LONG_TITLE', 'SEQ_NUM', 'DEATHTIME','ICUSTAY_AGE_GROUP',\n",
    "               'INTIME_ACTUAL','OUTTIME_ACTUAL',\"ADMISSION_TYPE\",'INSURANCE','CURR_CAREUNIT'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df2 (before key information is dropped) will be used for later analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mortality Basic Model (??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare variables for model\n",
    "y=df3['HOSPITAL_EXPIRE_FLAG']\n",
    "X=df3.drop(['HOSPITAL_EXPIRE_FLAG'],axis=1)\n",
    "\n",
    "# Split data in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_index = X_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_iter = IterativeImputer(random_state=0)\n",
    "imp_iter.fit(X_train)\n",
    "X_train = imp_iter.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_train.columns = df3.drop(['HOSPITAL_EXPIRE_FLAG'],axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.index = orig_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = imp_iter.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_test.columns = df3.drop(['HOSPITAL_EXPIRE_FLAG'],axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove some entries of class 0\n",
    "import random\n",
    "index_0 = [i for i in y_train[y_train == 0].index]\n",
    "index_1 = [i for i in y_train[y_train == 1].index]\n",
    "samp = random.sample(index_0, len(index_1))\n",
    "samp.extend(index_1)\n",
    "X_train = X_train.loc[samp,]\n",
    "y_train = y_train.loc[samp,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose columns to be scaled for X_train\n",
    "scale_columns = ['age','preiculos', 'gcs', 'heartrate', 'meanbp', 'resprate', 'temp',\n",
    "       'urineoutput', 'respiration',\n",
    "       'coagulation', 'liver', 'cardiovascular', 'cns', 'renal'] #,'DAYS_FROM_ADMISSION'\n",
    "scale_df = X_train[scale_columns]\n",
    "\n",
    "# Seperate the non-scaled columns (dummies) X_train\n",
    "temp = X_train.drop(scale_columns,axis=1)\n",
    "temp = temp.reset_index(drop=True)\n",
    "\n",
    "# Apply actual scaling to X_train\n",
    "scaler = preprocessing.StandardScaler().fit(scale_df) \n",
    "scale_tr = scaler.transform(scale_df) \n",
    "scale_df = pd.DataFrame(scale_tr,columns=scale_columns)\n",
    "\n",
    "# Add the non-scaled and scaled dataframes back together\n",
    "X_train = pd.concat([scale_df,temp], axis=1) \n",
    "\n",
    "#Choose columns to be scaled for X_test\n",
    "scale_df2 = X_test[scale_columns]\n",
    "\n",
    "# Seperate the non-scaled columns (dummies) X_test\n",
    "temp2 = X_test.drop(scale_columns,axis=1)\n",
    "temp2 = temp2.reset_index(drop=True)\n",
    "\n",
    "# Apply actual scaling to X_test\n",
    "# scaler2 = preprocessing.StandardScaler().fit(scale_df2) \n",
    "scale_tr2= scaler.transform(scale_df2) \n",
    "scale_df2=pd.DataFrame(scale_tr2,columns=scale_columns)\n",
    "\n",
    "# Add the non-scaled and scaled dataframes back together X_test\n",
    "X_test = pd.concat([scale_df2,temp2], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keyvanamini/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/keyvanamini/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.2577387786195686, tolerance: 0.0458\n",
      "  tol, rng, random, positive)\n"
     ]
    }
   ],
   "source": [
    "#Applying Lasso\n",
    "model_lasso = LassoCV(alphas=[1,0.1,0.01,0.0005]).fit(X_train, y_train) #variating through different alphas\n",
    "coef = pd.Series(model_lasso.coef_, index = X_train.columns)\n",
    "#y_pred_lasso = model_lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coefs= coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_group__>89              -0.183288\n",
       "careunit__CSRU              -0.075110\n",
       "gcs                         -0.059586\n",
       "urineoutput                 -0.048285\n",
       "gender__M                   -0.022819\n",
       "                               ...   \n",
       "careunit__SICU               0.136986\n",
       "age_group__65-89             0.155919\n",
       "mechvent                     0.165017\n",
       "DEATHRATE_CAT__2.0           0.175123\n",
       "ADMISSION_TYPE__EMERGENCY    0.222593\n",
       "Length: 61, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coefs.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5 = df5.drop(['DOB_ACTUAL','INTIME_ACTUAL','INTIME','OUTTIME','DOB','DOD','CHARTTIME','ICUSTAY_ID','SUBJECT_ID','HADM_ID','Diff','LAST_WARDID','GENDER','WARNING'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT!!!!\n",
    "# But one-hot encoding also presents two problems that are more particular to tree-based models:\n",
    "# The resulting sparsity virtually ensures that continuous variables are assigned higher feature importance.\n",
    "# A single level of a categorical variable must meet a very high bar in order to be selected for splitting early in the tree building. This can degrade predictive performance.\n",
    "\n",
    "feature_names = X_train.columns\n",
    "forest = RandomForestClassifier(n_estimators=20)  #Setting n_estimator to prevent overfitting\n",
    "forest_fitted = forest.fit(X_train, y_train) \n",
    "scores = cross_val_score(forest, X_train, y_train, cv=5)\n",
    "y_pred_forest = forest.predict(X_test)\n",
    "y_pred_prob = forest.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83 (+/- 0.03)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DEATHRATE_CAT__2.0          1.000000\n",
       "DEATHRATE_CAT__1.0          0.877121\n",
       "LOS                         0.702749\n",
       "SysBP_Min                   0.634665\n",
       "urineoutput                 0.583977\n",
       "                              ...   \n",
       "careunit__TSICU             0.026193\n",
       "age_group__>89              0.021392\n",
       "ADMISSION_TYPE__URGENT      0.003459\n",
       "INSURANCE_TYPE__Self Pay    0.003186\n",
       "DEATHRATE_INT_CAT__2.0      0.002902\n",
       "Length: 61, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Assess expected accuracy\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# Step 6: Assess variable importance\n",
    "importances = forest_fitted.feature_importances_\n",
    "important_features = pd.Series(data=importances/importances.max() ,index=feature_names)\n",
    "important_features.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOS Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LOS = df3.drop('HOSPITAL_EXPIRE_FLAG',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare variables for model\n",
    "y=df_LOS['LOS']\n",
    "X=df_LOS.drop(['LOS'],axis=1)\n",
    "\n",
    "# Split data in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_index = X_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_iter = IterativeImputer(random_state=0)\n",
    "imp_iter.fit(X_train)\n",
    "X_train = imp_iter.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_train.columns = df_LOS.drop(['LOS'],axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.index = orig_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = imp_iter.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_test.columns = df_LOS.drop(['LOS'],axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose columns to be scaled for X_train\n",
    "scale_columns = ['age','preiculos', 'gcs', 'heartrate', 'meanbp', 'resprate', 'temp',\n",
    "       'urineoutput', 'respiration',\n",
    "       'coagulation', 'liver', 'cardiovascular', 'cns', 'renal'] #,'DAYS_FROM_ADMISSION'\n",
    "scale_df = X_train[scale_columns]\n",
    "\n",
    "# Seperate the non-scaled columns (dummies) X_train\n",
    "temp = X_train.drop(scale_columns,axis=1)\n",
    "temp = temp.reset_index(drop=True)\n",
    "\n",
    "# Apply actual scaling to X_train\n",
    "scaler = preprocessing.StandardScaler().fit(scale_df) \n",
    "scale_tr = scaler.transform(scale_df) \n",
    "scale_df = pd.DataFrame(scale_tr,columns=scale_columns)\n",
    "\n",
    "# Add the non-scaled and scaled dataframes back together\n",
    "X_train = pd.concat([scale_df,temp], axis=1) \n",
    "\n",
    "#Choose columns to be scaled for X_test\n",
    "scale_df2 = X_test[scale_columns]\n",
    "\n",
    "# Seperate the non-scaled columns (dummies) X_test\n",
    "temp2 = X_test.drop(scale_columns,axis=1)\n",
    "temp2 = temp2.reset_index(drop=True)\n",
    "\n",
    "# Apply actual scaling to X_test\n",
    "# scaler2 = preprocessing.StandardScaler().fit(scale_df2) \n",
    "scale_tr2= scaler.transform(scale_df2) \n",
    "scale_df2=pd.DataFrame(scale_tr2,columns=scale_columns)\n",
    "\n",
    "# Add the non-scaled and scaled dataframes back together X_test\n",
    "X_test = pd.concat([scale_df2,temp2], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keyvanamini/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Applying Lasso\n",
    "model_lasso = LassoCV(alphas=[1,0.1,0.01,0.0005]).fit(X_train, y_train) #variating through different alphas\n",
    "coef = pd.Series(model_lasso.coef_, index = X_train.columns)\n",
    "#y_pred_lasso = model_lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coefs= coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "careunit__CSRU              -3.190885e-01\n",
       "DiasBP_Mean                 -8.047368e-02\n",
       "HeartRate_Mean              -5.405499e-02\n",
       "age                         -5.231764e-02\n",
       "gcs                         -3.389129e-02\n",
       "SysBP_Mean                  -1.745007e-02\n",
       "MeanBP_Min                  -1.565050e-02\n",
       "SysBP_Min                   -9.076468e-03\n",
       "MeanBP_Max                  -2.823552e-03\n",
       "Glucose_Min                 -1.681561e-03\n",
       "RespRate_Min                -6.156625e-05\n",
       "subject_id                  -6.686848e-06\n",
       "ADMISSION_TYPE__URGENT       0.000000e+00\n",
       "careunit__MICU              -0.000000e+00\n",
       "INSURANCE_TYPE__Self Pay    -0.000000e+00\n",
       "INSURANCE_TYPE__Private     -0.000000e+00\n",
       "RespRate_Max                -0.000000e+00\n",
       "TempC_Min                   -0.000000e+00\n",
       "TempC_Mean                   0.000000e+00\n",
       "SpO2_Max                    -0.000000e+00\n",
       "INSURANCE_TYPE__Medicare     0.000000e+00\n",
       "age_group__40-64             0.000000e+00\n",
       "age_group__65-89             0.000000e+00\n",
       "age_group__>89              -0.000000e+00\n",
       "INSURANCE_TYPE__Medicaid     0.000000e+00\n",
       "gender__M                   -0.000000e+00\n",
       "careunit__TSICU              0.000000e+00\n",
       "temp                         0.000000e+00\n",
       "coagulation                  0.000000e+00\n",
       "preiculos                    0.000000e+00\n",
       "heartrate                    0.000000e+00\n",
       "electivesurgery             -0.000000e+00\n",
       "meanbp                       0.000000e+00\n",
       "resprate                    -0.000000e+00\n",
       "DEATHRATE_INT_CAT__2.0      -0.000000e+00\n",
       "DEATHRATE_INT_CAT__1.0       0.000000e+00\n",
       "DEATHRATE_CAT__2.0           0.000000e+00\n",
       "hadm_id                      9.879207e-07\n",
       "Glucose_Max                  6.980268e-04\n",
       "Glucose_Mean                 1.399485e-03\n",
       "cns                          5.529153e-03\n",
       "DiasBP_Max                   6.194666e-03\n",
       "DiasBP_Min                   7.724978e-03\n",
       "SysBP_Max                    1.022284e-02\n",
       "SpO2_Min                     1.264122e-02\n",
       "ADMISSION_TYPE__EMERGENCY    1.643118e-02\n",
       "HeartRate_Max                3.155522e-02\n",
       "HeartRate_Min                4.120600e-02\n",
       "renal                        5.481884e-02\n",
       "SpO2_Mean                    6.573050e-02\n",
       "liver                        1.038310e-01\n",
       "MeanBP_Mean                  1.161076e-01\n",
       "RespRate_Mean                1.198261e-01\n",
       "urineoutput                  1.479124e-01\n",
       "careunit__SICU               2.202456e-01\n",
       "respiration                  2.562075e-01\n",
       "TempC_Max                    3.143788e-01\n",
       "cardiovascular               5.530103e-01\n",
       "DEATHRATE_CAT__1.0           1.418829e+00\n",
       "mechvent                     1.547955e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coefs.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5 = df5.drop(['DOB_ACTUAL','INTIME_ACTUAL','INTIME','OUTTIME','DOB','DOD','CHARTTIME','ICUSTAY_ID','SUBJECT_ID','HADM_ID','Diff','LAST_WARDID','GENDER','WARNING'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT!!!!\n",
    "# But one-hot encoding also presents two problems that are more particular to tree-based models:\n",
    "# The resulting sparsity virtually ensures that continuous variables are assigned higher feature importance.\n",
    "# A single level of a categorical variable must meet a very high bar in order to be selected for splitting early in the tree building. This can degrade predictive performance.\n",
    "\n",
    "feature_names = X_train.columns\n",
    "forest = RandomForestRegressor(n_estimators=20)  #Setting n_estimator to prevent overfitting\n",
    "forest_fitted = forest.fit(X_train, y_train) \n",
    "scores = cross_val_score(forest, X_train, y_train, cv=5, scoring='r2')\n",
    "y_pred_forest = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.12 (+/- 0.09)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mechvent                     1.000000\n",
       "urineoutput                  0.653505\n",
       "RespRate_Mean                0.650406\n",
       "DEATHRATE_CAT__1.0           0.638843\n",
       "Glucose_Min                  0.430210\n",
       "subject_id                   0.424644\n",
       "HeartRate_Max                0.416856\n",
       "Glucose_Max                  0.407509\n",
       "liver                        0.397903\n",
       "cardiovascular               0.383089\n",
       "hadm_id                      0.361387\n",
       "SpO2_Mean                    0.340242\n",
       "Glucose_Mean                 0.325731\n",
       "DiasBP_Mean                  0.321939\n",
       "TempC_Max                    0.314150\n",
       "age                          0.307847\n",
       "HeartRate_Mean               0.299760\n",
       "SysBP_Mean                   0.285916\n",
       "preiculos                    0.284322\n",
       "respiration                  0.278228\n",
       "TempC_Mean                   0.277735\n",
       "HeartRate_Min                0.273690\n",
       "heartrate                    0.265874\n",
       "SpO2_Min                     0.260975\n",
       "SysBP_Max                    0.255541\n",
       "careunit__CSRU               0.253523\n",
       "SysBP_Min                    0.243422\n",
       "MeanBP_Mean                  0.237806\n",
       "DiasBP_Min                   0.225820\n",
       "DiasBP_Max                   0.224578\n",
       "meanbp                       0.222111\n",
       "MeanBP_Min                   0.218903\n",
       "RespRate_Min                 0.210255\n",
       "TempC_Min                    0.193420\n",
       "MeanBP_Max                   0.185100\n",
       "gcs                          0.173702\n",
       "RespRate_Max                 0.163558\n",
       "temp                         0.161981\n",
       "resprate                     0.140927\n",
       "renal                        0.098707\n",
       "SpO2_Max                     0.097880\n",
       "coagulation                  0.089203\n",
       "cns                          0.069405\n",
       "careunit__SICU               0.061435\n",
       "electivesurgery              0.060603\n",
       "gender__M                    0.053971\n",
       "INSURANCE_TYPE__Medicaid     0.042387\n",
       "careunit__TSICU              0.032138\n",
       "INSURANCE_TYPE__Medicare     0.031970\n",
       "INSURANCE_TYPE__Private      0.029418\n",
       "DEATHRATE_CAT__2.0           0.025559\n",
       "age_group__65-89             0.022270\n",
       "age_group__40-64             0.018763\n",
       "DEATHRATE_INT_CAT__2.0       0.016744\n",
       "DEATHRATE_INT_CAT__1.0       0.014907\n",
       "ADMISSION_TYPE__EMERGENCY    0.014111\n",
       "ADMISSION_TYPE__URGENT       0.013488\n",
       "careunit__MICU               0.013118\n",
       "age_group__>89               0.005787\n",
       "INSURANCE_TYPE__Self Pay     0.002611\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Assess expected accuracy\n",
    "print(\"R2 Score: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# Step 6: Assess variable importance\n",
    "importances = forest_fitted.feature_importances_\n",
    "important_features = pd.Series(data=importances/importances.max() ,index=feature_names)\n",
    "important_features.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only takes the first three characters from ICD9_Code as the rest is only decimal points \n",
    "#(https://mimic.physionet.org/mimictables/diagnoses_icd/)\n",
    "df2['ICD9_CODE'] = df2['ICD9_CODE'].apply(lambda x: x[:3])\n",
    "# Converts ICD9 Codes of type \"O\" to integer in case string contains only digits, else None\n",
    "df2['ICD9_CODE'] = df2['ICD9_CODE'].apply(lambda x: int(x) if str(x).isdigit() else None)\n",
    "\n",
    "def f(x):\n",
    "    if x['ICD9_CODE'] > 1 and x['ICD9_CODE'] < 139: return 'Infectious And Parasitic Diseases'\n",
    "    elif x['ICD9_CODE'] > 140 and x['ICD9_CODE'] < 239: return 'Neoplasms'\n",
    "    elif x['ICD9_CODE'] > 240 and x['ICD9_CODE'] < 279: return 'Endocrine, Nutritional And Metabolic Diseases, And Immunity Disorders'\n",
    "    elif x['ICD9_CODE'] > 280 and x['ICD9_CODE'] < 289: return 'Diseases Of The Blood And Blood-Forming Organs'\n",
    "    elif x['ICD9_CODE'] > 290 and x['ICD9_CODE'] < 319: return 'Mental Disorders'\n",
    "    elif x['ICD9_CODE'] > 320 and x['ICD9_CODE'] < 389: return 'Diseases Of The Nervous System And Sense Organs'\n",
    "    elif x['ICD9_CODE'] > 390 and x['ICD9_CODE'] < 459: return 'Diseases Of The Circulatory System'\n",
    "    elif x['ICD9_CODE'] > 460 and x['ICD9_CODE'] < 519: return 'Diseases Of The Respiratory System'\n",
    "    elif x['ICD9_CODE'] > 520 and x['ICD9_CODE'] < 579: return 'Diseases Of The Digestive System'\n",
    "    elif x['ICD9_CODE'] > 580 and x['ICD9_CODE'] < 629: return 'Diseases Of The Genitourinary System'\n",
    "    elif x['ICD9_CODE'] > 630 and x['ICD9_CODE'] < 679: return 'Complications Of Pregnancy, Childbirth, And The Puerperium'\n",
    "    elif x['ICD9_CODE'] > 680 and x['ICD9_CODE'] < 709: return 'Diseases Of The Skin And Subcutaneous Tissue'\n",
    "    elif x['ICD9_CODE'] > 710 and x['ICD9_CODE'] < 739: return 'Diseases Of The Musculoskeletal System And Connective Tissue'\n",
    "    elif x['ICD9_CODE'] > 740 and x['ICD9_CODE'] < 759: return 'Congenital Anomalies'\n",
    "    elif x['ICD9_CODE'] > 760 and x['ICD9_CODE'] < 779: return 'Certain Conditions Originating In The Perinatal Period'\n",
    "    elif x['ICD9_CODE'] > 780 and x['ICD9_CODE'] < 799: return 'Symptoms, Signs, And Ill-Defined Conditions'\n",
    "    elif x['ICD9_CODE'] > 800 and x['ICD9_CODE'] < 999: return 'Injury And Poisoning'\n",
    "    else: return \"Other\"\n",
    "df2['ICD9_CODE_CAT'] = df2.apply(f, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "icustay_ids = [f for f in df2['ICUSTAY_ID']]\n",
    "intimes = [t.date() for t in df2['INTIME_ACTUAL']]\n",
    "outtimes = [t.date() for t in df2['OUTTIME_ACTUAL']]\n",
    "expire_flags = [f for f in df2['HOSPITAL_EXPIRE_FLAG']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading snapshots dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snapshots = pd.read_csv(\"df_snapshots.csv\")\n",
    "df_snapshots = df_snapshots.reset_index()\n",
    "df_snapshots = df_snapshots.drop('index',axis=1)\n",
    "df_snapshots['icustay_id']=np.int64(df_snapshots['icustay_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop('icustay_id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.merge(df_snapshots, 'outer', left_on='ICUSTAY_ID', right_on='icustay_id').drop('icustay_id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Encoding\n",
    "diagnosis_encoder = BinaryEncoder()\n",
    "diagnosis_binary = diagnosis_encoder.fit_transform(df3['ICD9_CODE_CAT'].astype(str))\n",
    "df3 = pd.concat([df3,diagnosis_binary], axis=1) #, diagnosis_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataframe with caregivers_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "caregivers_count_df = pd.read_csv(\"caregivers_count_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "caretime_doctors = [d/p for d,p in zip(caregivers_count_df['COUNT_DOCTORS'], caregivers_count_df['COUNT_PATIENTS'])]\n",
    "caretime_nurses = [n/p for n,p in zip(caregivers_count_df['COUNT_NURSES'], caregivers_count_df['COUNT_PATIENTS'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keyvanamini/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/keyvanamini/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "caretime_df = caregivers_count_df[['DATE']]\n",
    "caretime_df['caretime_doctors'] = caretime_doctors\n",
    "caretime_df['caretime_nurses'] = caretime_nurses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3 = df3.merge(caregivers_count_df, how='left', left_on='date',right_on=\"DATE\")\n",
    "df3 = df3.merge(caretime_df, how='left', left_on='date',right_on=\"DATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_caretime = df3[['ICUSTAY_ID','DATE','caretime_doctors','caretime_nurses']].groupby(['ICUSTAY_ID','DATE']).sum().groupby('ICUSTAY_ID').cumsum()\n",
    "cum_caretime = pd.DataFrame(cum_caretime.to_records())\n",
    "cum_caretime.columns = ['ICUSTAY_ID', 'DATE', 'cum_caretime_doctors', 'cum_caretime_nurses']\n",
    "df3 = df3.merge(cum_caretime,how='inner',on=['ICUSTAY_ID','DATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading procedures dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedures_df = pd.read_csv(\"procedures.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = procedures_df.columns.tolist()\n",
    "cols.append('days_since_admission')\n",
    "procedures_df2 = pd.DataFrame(columns = cols)\n",
    "\n",
    "for i in range(procedures_df.shape[0]):\n",
    "    entry_i = procedures_df.loc[[i]]\n",
    "    df_i = procedures_df.loc[i]\n",
    "    all_i = pd.concat([entry_i]*(df_i['DAYSIN_END']-df_i['DAYSIN_START']+1))\n",
    "    days = np.arange(df_i['DAYSIN_START'],df_i['DAYSIN_END']+1)\n",
    "    all_i['days_since_admission'] = days\n",
    "    procedures_df2 = pd.concat([procedures_df2, all_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedures_df3 = procedures_df2.reset_index().drop(['index','ITEMID','LABEL','DAYSIN_START','DAYSIN_END'],axis=1)\n",
    "procedures_dummies = pd.get_dummies(procedures_df3['ORDERCATEGORYNAME'],prefix='procedure')\n",
    "procedures_df4 = pd.concat([procedures_df3,procedures_dummies],axis=1)\n",
    "procedures_df4 = procedures_df4.drop(['SUBJECT_ID','HADM_ID','ORDERCATEGORYNAME'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedures_df4['ICUSTAY_ID'] = procedures_df4['ICUSTAY_ID'].astype('int64')\n",
    "procedures_df4['days_since_admission'] = procedures_df4['days_since_admission'].astype('int64')\n",
    "procedures_df4 = procedures_df4.rename(columns={'procedure_Significant Events':'procedure_SignificantEvents'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "procedures_df5 = procedures_df4.groupby(['ICUSTAY_ID','days_since_admission']).sum().reset_index()\n",
    "procedures_df5['procedure_SignificantEvents'] = procedures_df5['procedure_SignificantEvents'].where(procedures_df5['procedure_SignificantEvents'] < 1, 1)\n",
    "procedures_df5['procedure_Ventilation'] = procedures_df5['procedure_Ventilation'].where(procedures_df5['procedure_Ventilation'] < 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df4 = df3.merge(procedures_df5,how='left',on=['ICUSTAY_ID','days_since_admission'])\n",
    "df4[['procedure_SignificantEvents', 'procedure_Ventilation']] = df4[['procedure_SignificantEvents','procedure_Ventilation']].fillna(value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simulations\n",
    "df6 = df4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4.drop(['HOSPITAL_EXPIRE_FLAG','hospital_expire_flag','subject_id', 'hadm_id',\n",
    "               'ICUSTAY_ID', 'SUBJECT_ID', 'HADM_ID', 'INTIME', 'OUTTIME', 'DIFF',\n",
    "               'LAST_WARDID', 'GENDER','DOB', 'ICD9_CODE', 'SHORT_TITLE',\n",
    "               'LONG_TITLE', 'SEQ_NUM', 'DEATHTIME','ICUSTAY_AGE_GROUP',\n",
    "               'ICD9_CODE_CAT','date',\n",
    "               'INTIME_ACTUAL', 'OUTTIME_ACTUAL',\"CURR_CAREUNIT\",\"INSURANCE\",\"ADMISSION_TYPE\",\"DATE\",\"LOS\",\n",
    "               'caretime_doctors','caretime_nurses'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare variables for model\n",
    "y=df4['out_flag']\n",
    "X=df4.drop(['out_flag'],axis=1)\n",
    "\n",
    "# Split data in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_index = X_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_iter = IterativeImputer(random_state=0)\n",
    "imp_iter.fit(X_train)\n",
    "X_train = imp_iter.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_train.columns = df4.drop(['out_flag'],axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.index = orig_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = imp_iter.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_test.columns = df4.drop(['out_flag'],axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "y_train_orig = copy.deepcopy(y_train)\n",
    "X_train_orig = copy.deepcopy(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove some entries of class 0\n",
    "import random\n",
    "index_0 = [i for i in y_train[y_train == 0].index]\n",
    "index_1 = [i for i in y_train[y_train == 1].index]\n",
    "index_neg1 = [i for i in y_train[y_train == -1].index]\n",
    "samp = random.sample(index_0, len(index_1))\n",
    "samp_neg1 = random.sample(index_neg1, len(index_1))\n",
    "samp.extend(samp_neg1)\n",
    "samp.extend(index_1)\n",
    "X_train = X_train.loc[samp,]\n",
    "y_train = y_train.loc[samp,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose columns to be scaled for X_train\n",
    "scale_columns = ['age','preiculos', 'gcs', 'heartrate', 'meanbp', 'resprate', 'temp',\n",
    "       'urineoutput', 'respiration',\n",
    "       'coagulation', 'liver', 'cardiovascular', 'cns', 'renal',\n",
    "                'HeartRate_Min', 'HeartRate_Max',\n",
    "       'HeartRate_Mean', 'SysBP_Min', 'SysBP_Max', 'SysBP_Mean', 'DiasBP_Min',\n",
    "       'DiasBP_Max', 'DiasBP_Mean', 'MeanBP_Min', 'MeanBP_Max', 'MeanBP_Mean',\n",
    "       'RespRate_Min', 'RespRate_Max', 'RespRate_Mean', 'TempC_Min',\n",
    "       'TempC_Max', 'TempC_Mean', 'SpO2_Min', 'SpO2_Max', 'SpO2_Mean',\n",
    "       'Glucose_Min', 'Glucose_Max', 'Glucose_Mean','days_since_admission',\n",
    "                'cum_caretime_doctors','cum_caretime_nurses'] \n",
    "scale_df = X_train[scale_columns]\n",
    "\n",
    "# Seperate the non-scaled columns (dummies) X_train\n",
    "temp = X_train.drop(scale_columns,axis=1)\n",
    "temp = temp.reset_index(drop=True)\n",
    "\n",
    "# Apply actual scaling to X_train\n",
    "scaler = preprocessing.StandardScaler().fit(scale_df) \n",
    "scale_tr = scaler.transform(scale_df) \n",
    "scale_df = pd.DataFrame(scale_tr,columns=scale_columns)\n",
    "\n",
    "# Add the non-scaled and scaled dataframes back together\n",
    "X_train = pd.concat([scale_df,temp], axis=1) \n",
    "\n",
    "#Choose columns to be scaled for X_test\n",
    "scale_df2 = X_test[scale_columns]\n",
    "\n",
    "# Seperate the non-scaled columns (dummies) X_test\n",
    "temp2 = X_test.drop(scale_columns,axis=1)\n",
    "temp2 = temp2.reset_index(drop=True)\n",
    "\n",
    "# Apply actual scaling to X_test\n",
    "# scaler2 = preprocessing.StandardScaler().fit(scale_df2) \n",
    "scale_tr2= scaler.transform(scale_df2) \n",
    "scale_df2=pd.DataFrame(scale_tr2,columns=scale_columns)\n",
    "\n",
    "# Add the non-scaled and scaled dataframes back together X_test\n",
    "X_test = pd.concat([scale_df2,temp2], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [2 if y==-1 else y for y in y_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sub = X_train.copy()\n",
    "y_train_sub = y_train.copy()\n",
    "X_test_sub = X_test.copy()\n",
    "y_test_sub = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_cols = ['days_since_admission','procedure_SignificantEvents', 'procedure_Ventilation',\n",
    "#               'COUNT_DOCTORS', 'COUNT_NURSES', 'COUNT_PATIENTS',\n",
    "            'cum_caretime_doctors','cum_caretime_nurses']\n",
    "col_ord = [c for c in X_train_sub.columns if c not in back_cols]\n",
    "col_ord.extend(back_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sub = X_train_sub.loc[:,col_ord]\n",
    "X_test_sub = X_test_sub.loc[:,col_ord]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train_sub.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT!!!!\n",
    "# But one-hot encoding also presents two problems that are more particular to tree-based models:\n",
    "# The resulting sparsity virtually ensures that continuous variables are assigned higher feature importance.\n",
    "# A single level of a categorical variable must meet a very high bar in order to be selected for splitting early in the tree building. This can degrade predictive performance.\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=20)  #Setting n_estimator to prevent overfitting\n",
    "forest_fitted = forest.fit(X_train_sub, y_train_sub) \n",
    "scores = cross_val_score(forest, X_train_sub, y_train_sub, cv=5)\n",
    "y_pred_forest = forest.predict(X_test_sub)\n",
    "y_pred_prob = forest.predict_proba(X_test_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.64 (+/- 0.03)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cum_caretime_nurses         1.000000\n",
       "days_since_admission        0.853092\n",
       "urineoutput                 0.840730\n",
       "cum_caretime_doctors        0.766916\n",
       "DEATHRATE_CAT__2.0          0.759491\n",
       "                              ...   \n",
       "age_group__>89              0.019415\n",
       "ICD9_CODE_CAT_1             0.010685\n",
       "ADMISSION_TYPE__URGENT      0.008821\n",
       "INSURANCE_TYPE__Self Pay    0.006586\n",
       "ICD9_CODE_CAT_0             0.000000\n",
       "Length: 69, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Assess expected accuracy\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# Step 6: Assess variable importance\n",
    "importances = forest_fitted.feature_importances_\n",
    "important_features = pd.Series(data=importances/importances.max() ,index=feature_names)\n",
    "important_features.sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# IMPORTANT!!!!\n",
    "# But one-hot encoding also presents two problems that are more particular to tree-based models:\n",
    "# The resulting sparsity virtually ensures that continuous variables are assigned higher feature importance.\n",
    "# A single level of a categorical variable must meet a very high bar in order to be selected for splitting early in the tree building. This can degrade predictive performance.\n",
    "\n",
    "feature_names = X_train.columns\n",
    "tree = GradientBoostingClassifier(n_estimators=50)  #Setting n_estimator to prevent overfitting\n",
    "tree_fitted = tree.fit(X_train, y_train) \n",
    "scores = cross_val_score(tree, X_train, y_train, cv=5)\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "y_pred_prob_tree = tree.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67 (+/- 0.02)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cum_caretime_nurses        1.000000\n",
       "DEATHRATE_CAT__2.0         0.999684\n",
       "procedure_Ventilation      0.802447\n",
       "urineoutput                0.758010\n",
       "DEATHRATE_CAT__1.0         0.487739\n",
       "                             ...   \n",
       "ICD9_CODE_CAT_4            0.000000\n",
       "ADMISSION_TYPE__URGENT     0.000000\n",
       "ICD9_CODE_CAT_0            0.000000\n",
       "age_group__65-89           0.000000\n",
       "INSURANCE_TYPE__Private    0.000000\n",
       "Length: 69, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Assess expected accuracy\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# Step 6: Assess variable importance\n",
    "importances = tree_fitted.feature_importances_\n",
    "important_features = pd.Series(data=importances/importances.max() ,index=feature_names)\n",
    "important_features.sort_values(ascending=False)\n",
    "\n",
    "#print(\"Confusion matrix\")\n",
    "#cm=confusion_matrix(y_test,y_pred_lasso)\n",
    "#plot_confusion_matrix(cm, ['1','2'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softprob',\n",
    "              learning_rate= 0.05, #so called `eta` value\n",
    "              max_depth= 6,\n",
    "              min_child_weight= 11,\n",
    "              silent= 1,\n",
    "              subsample= 0.8,\n",
    "              colsample_bytree= 0.7,\n",
    "              n_estimators= 50, #number of trees \n",
    "              missing=-999, #replacing missing values\n",
    "              reg_lambda=1.5,\n",
    "              seed= 1337)\n",
    "\n",
    "xgb_model.fit(X_train,y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_pred_prob_xgb = xgb_model.predict_proba(X_test)\n",
    "scores = cross_val_score(xgb_model, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68 (+/- 0.02)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "procedure_Ventilation       1.000000\n",
       "DEATHRATE_CAT__2.0          0.736445\n",
       "DEATHRATE_CAT__1.0          0.594413\n",
       "cardiovascular              0.315108\n",
       "DEATHRATE_INT_CAT__1.0      0.309325\n",
       "                              ...   \n",
       "ICD9_CODE_CAT_1             0.000000\n",
       "ICD9_CODE_CAT_0             0.000000\n",
       "age_group__>89              0.000000\n",
       "INSURANCE_TYPE__Self Pay    0.000000\n",
       "careunit__TSICU             0.000000\n",
       "Length: 69, dtype: float32"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "importances = xgb_model.feature_importances_\n",
    "important_features = pd.Series(data=importances/importances.max() ,index=feature_names)\n",
    "important_features.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Grid Search CV\n",
    "\n",
    "# MySvc = SVC()\n",
    "# grid_values = {'kernel':['rbf','linear'],\n",
    "#                'C':[1,10,100] #, 'gamma':[0.05, 0.1, 0.25, 0.5], \n",
    "#                #'decision_function_shape':['ovr','ovo'],\n",
    "#                #'class_weight':['balanced',inv_weight,arith_weight]\n",
    "#               } # Parameter grid here, default gamma = 1/(num features)\n",
    "# grid_svc_acc = GridSearchCV(MySvc, param_grid = grid_values,scoring = 'accuracy', cv=5)\n",
    "# grid_svc_acc.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "# #Best parameters\n",
    "# print('Best Cost parameter : '+ str(grid_svc_acc.best_estimator_.C))\n",
    "# print('Best gamma parameter : '+ str(grid_svc_acc.best_estimator_.gamma))\n",
    "\n",
    "# # Report best Number of Neighbors\n",
    "# GridSearch_table_plot(grid_svc_acc, \"C\", negative=False, display_all_params=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-af3f27319ea9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelper_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# GridSearch_table_plot(grid_svc_acc, \"C\", negative=False, display_all_params=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "#from utils.helper_functions import *\n",
    "\n",
    "# GridSearch_table_plot(grid_svc_acc, \"C\", negative=False, display_all_params=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keyvanamini/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classifier = SVC(kernel ='linear', C=10, probability=True) \n",
    "classifier = SVC(kernel ='rbf', C=0.1, probability=True)\n",
    "classifier.fit(X_train_sub, y_train_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26365216, 0.11240327, 0.62394457],\n",
       "       [0.18203506, 0.74428325, 0.07368169],\n",
       "       [0.37040548, 0.46823854, 0.16135599],\n",
       "       ...,\n",
       "       [0.57351634, 0.22248023, 0.20400343],\n",
       "       [0.48796074, 0.17424483, 0.33779442],\n",
       "       [0.49913405, 0.06412574, 0.43674022]])"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(X_test_sub)\n",
    "classifier.predict_proba(X_test_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_svm (X_new,rew):\n",
    "    \n",
    "    # Choose columns to be scaled for X_train\n",
    "    scale_columns = ['age','preiculos', 'gcs', 'heartrate', 'meanbp', 'resprate', 'temp',\n",
    "           'urineoutput', 'respiration',\n",
    "           'coagulation', 'liver', 'cardiovascular', 'cns', 'renal',\n",
    "                    'HeartRate_Min', 'HeartRate_Max',\n",
    "           'HeartRate_Mean', 'SysBP_Min', 'SysBP_Max', 'SysBP_Mean', 'DiasBP_Min',\n",
    "           'DiasBP_Max', 'DiasBP_Mean', 'MeanBP_Min', 'MeanBP_Max', 'MeanBP_Mean',\n",
    "           'RespRate_Min', 'RespRate_Max', 'RespRate_Mean', 'TempC_Min',\n",
    "           'TempC_Max', 'TempC_Mean', 'SpO2_Min', 'SpO2_Max', 'SpO2_Mean',\n",
    "           'Glucose_Min', 'Glucose_Max', 'Glucose_Mean','days_since_admission',\n",
    "                    'cum_caretime_doctors','cum_caretime_nurses'] \n",
    "    scale_df = X_new[scale_columns]\n",
    "\n",
    "    # Seperate the non-scaled columns (dummies) X_train\n",
    "    temp = X_new.drop(scale_columns,axis=1)\n",
    "    temp = temp.reset_index(drop=True)\n",
    "\n",
    "    # Apply actual scaling to X_train\n",
    "    scale_tr = scaler.transform(scale_df) \n",
    "    scale_df = pd.DataFrame(scale_tr,columns=scale_columns)\n",
    "\n",
    "    # Add the non-scaled and scaled dataframes back together\n",
    "    X_new = pd.concat([scale_df,temp], axis=1) \n",
    "    X_new = X_new.loc[:,col_ord]\n",
    "\n",
    "    y_pred_prob = classifier.predict_proba(X_new)\n",
    "    if rew:\n",
    "        y_pred = []\n",
    "        for i in range(X_new.shape[0]):\n",
    "            if np.argmax(y_pred_prob[i,]) == 0:\n",
    "                y_pred.append(0)\n",
    "            elif np.argmax(y_pred_prob[i,]) == 1:\n",
    "                y_pred.append(1)\n",
    "            elif y_pred_prob[i,2] > 10*y_pred_prob[i,1]:\n",
    "                y_pred.append(2)\n",
    "            else:\n",
    "                y_pred.append(1)\n",
    "    else:\n",
    "        y_pred = [np.argmax(y_pred_prob[i,]) for i in range(X_new.shape[0])]\n",
    "    return(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlens.ensemble import SuperLearner\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    #Generate a library of simple learners\n",
    "    rf = RandomForestClassifier(n_estimators=20)\n",
    "    tree = GradientBoostingClassifier(n_estimators=50)\n",
    "    xgb_mod = xgb.XGBClassifier(objective='multi:softprob',\n",
    "              learning_rate= 0.05, #so called `eta` value\n",
    "              max_depth= 6,\n",
    "              min_child_weight= 11,\n",
    "              silent= 1,\n",
    "              subsample= 0.8,\n",
    "              colsample_bytree= 0.7,\n",
    "              n_estimators= 50, #number of trees \n",
    "              missing=-999, #replacing missing values\n",
    "              reg_lambda=1.5,\n",
    "              seed= 1337)\n",
    "#     svc = SVC(C=10, kernel='linear', probability=True, gamma='scale', random_state=1)\n",
    "#     lr = LogisticRegression(penalty='l2', C=100.0, \n",
    "#                            fit_intercept=True, \n",
    "#                            intercept_scaling=1, \n",
    "#                            solver='liblinear', max_iter=500)\n",
    "\n",
    "    models = {'random forest': rf,\n",
    "              'gradient boosting': tree,\n",
    "              'xgboost': xgb_mod,\n",
    "#               'svc':svc,\n",
    "#               'logistic': lr,\n",
    "              }\n",
    "\n",
    "    return models\n",
    "\n",
    "models = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner = ExtraTreesClassifier(\n",
    "    n_estimators=50,\n",
    "    bootstrap=True,\n",
    "    max_features=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['days_since_admission', 'procedure_SignificantEvents',\n",
       "       'procedure_Ventilation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select features to propagate\n",
    "to_propagate=['days_since_admission','procedure_Ventilation','procedure_SignificantEvents'] # you can add the most important according to random forest, for example\n",
    "pointer= [i for i,x in enumerate(X_train_sub.columns) if x in to_propagate]\n",
    "X_train_sub.columns[pointer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the ensemble with 5 folds (stacking meta-learner)\n",
    "sl = SuperLearner(\n",
    "    folds=5,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Add the base learners and the meta learner\n",
    "sl.add(list(models.values()), proba=True, propagate_features=pointer)\n",
    "sl.add_meta(meta_learner, proba=True)\n",
    "\n",
    "# Train the ensemble\n",
    "sl.fit(np.array(X_train_sub), np.array(y_train_sub))\n",
    "\n",
    "y_pred_prob_sl = sl.predict_proba(np.array(X_test_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5 , 0.2 , 0.3 ],\n",
       "       [0.16, 0.78, 0.06],\n",
       "       [0.88, 0.06, 0.06],\n",
       "       ...,\n",
       "       [0.36, 0.6 , 0.04],\n",
       "       [0.16, 0.52, 0.32],\n",
       "       [0.08, 0.64, 0.28]], dtype=float32)"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sl = [np.argmax(y_pred_prob_sl[i,]) for i in range(y_pred_prob_sl.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reweight(pi0,pi1,pi2,q0=0.5,r0=0.5,q1=0.5,r1=0.5,q2=0.5,r2=0.5):\n",
    "    tot = pi0*(q0/r0)+pi1*(q1/r1)+pi2*(q2/r2)\n",
    "    w0 = pi0*(q0/r0)\n",
    "    w1 = pi1*(q1/r1)\n",
    "    w2 = pi2*(q2/r2)\n",
    "    w0 /= tot\n",
    "    w1 /= tot\n",
    "    w2 /= tot\n",
    "    return w0,w1,w2\n",
    "\n",
    "# # Reweight class prediction probability\n",
    "\n",
    "# pred_rew_prob = reweight(y_pred_prob[:,1], q1, r1) #[i for i in \n",
    "# # y_pred_prob = np.append(y_pred_prob, np.atleast_2d(pred_rew_prob).T, axis=1)\n",
    "# # Classification\n",
    "# pred_rew = [1 if i>0.5 else 0 for i in pred_rew_prob]\n",
    "\n",
    "# pred_prob = y_pred_prob[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction (X_new,rew,q0,r0,q1,r1,q2,r2):\n",
    "    \n",
    "    # Choose columns to be scaled for X_train\n",
    "    scale_columns = ['age','preiculos', 'gcs', 'heartrate', 'meanbp', 'resprate', 'temp',\n",
    "           'urineoutput', 'respiration',\n",
    "           'coagulation', 'liver', 'cardiovascular', 'cns', 'renal',\n",
    "                    'HeartRate_Min', 'HeartRate_Max',\n",
    "           'HeartRate_Mean', 'SysBP_Min', 'SysBP_Max', 'SysBP_Mean', 'DiasBP_Min',\n",
    "           'DiasBP_Max', 'DiasBP_Mean', 'MeanBP_Min', 'MeanBP_Max', 'MeanBP_Mean',\n",
    "           'RespRate_Min', 'RespRate_Max', 'RespRate_Mean', 'TempC_Min',\n",
    "           'TempC_Max', 'TempC_Mean', 'SpO2_Min', 'SpO2_Max', 'SpO2_Mean',\n",
    "           'Glucose_Min', 'Glucose_Max', 'Glucose_Mean','days_since_admission',\n",
    "                    'cum_caretime_doctors','cum_caretime_nurses'] \n",
    "    scale_df = X_new[scale_columns]\n",
    "\n",
    "    # Seperate the non-scaled columns (dummies) X_train\n",
    "    temp = X_new.drop(scale_columns,axis=1)\n",
    "    temp = temp.reset_index(drop=True)\n",
    "\n",
    "    # Apply actual scaling to X_train\n",
    "    scale_tr = scaler.transform(scale_df) \n",
    "    scale_df = pd.DataFrame(scale_tr,columns=scale_columns)\n",
    "\n",
    "    # Add the non-scaled and scaled dataframes back together\n",
    "    X_new = pd.concat([scale_df,temp], axis=1) \n",
    "        \n",
    "    X_new2 = X_new.loc[:,col_ord]\n",
    "    \n",
    "    for i in range(4):\n",
    "        X_new2 = pd.concat([X_new2,X_new],axis=0)\n",
    "        \n",
    "    y_pred_prob = sl.predict_proba(np.array(X_new2))\n",
    "    \n",
    "    if rew:\n",
    "    \n",
    "        rew0 = []\n",
    "        rew1 = []\n",
    "        rew2 = []\n",
    "\n",
    "        for i in range(X_new.shape[0]):\n",
    "            pi0,pi1,pi2 = y_pred_prob[i]\n",
    "            w0,w1,w2 = reweight(pi0,pi1,pi2,q0,r0,q1,r1,q2,r2)\n",
    "            rew0.append(w0)\n",
    "            rew1.append(w1)\n",
    "            rew2.append(w2)    \n",
    "\n",
    "        pred_rew = [np.argmax([a,b,c]) for a,b,c in zip(rew0,rew1,rew2)]\n",
    "        return(pred_rew)\n",
    "    \n",
    "    else:\n",
    "        y_pred = [np.argmax(y_pred_prob[i,]) for i in range(X_new.shape[0])]\n",
    "        return(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_orig = [2 if y==-1 else y for y in y_train_orig]\n",
    "\n",
    "#Population ratios\n",
    "q0 = np.sum([y==0 for y in y_train_orig])/len(y_train_orig)\n",
    "q1 = np.sum([y==1 for y in y_train_orig])/len(y_train_orig)\n",
    "q2 = np.sum([y==2 for y in y_train_orig])/len(y_train_orig)\n",
    "\n",
    "r0 = 1/3 # training set\n",
    "r1 = 1/3 # training set\n",
    "r2 = 1/3 # training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction_svm(X_test_sub.loc[[11]],False,q0,r0,q1,r1,q2,r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob =  classifier.predict_proba(X_test_sub)\n",
    "y_pred_forest = classifier.predict(X_test_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "rew0 = []\n",
    "rew1 = []\n",
    "rew2 = []\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    pi0,pi1,pi2 = y_pred_prob[i]\n",
    "    w0,w1,w2 = reweight(pi0,pi1,pi2,q0,r0,q1,r1,q2,r2)\n",
    "    rew0.append(w0)\n",
    "    rew1.append(w1)\n",
    "    rew2.append(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rew = [np.argmax([a,b,c]) for a,b,c in zip(rew0,rew1,rew2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8265, 0, 12)"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([p == 0 for p in pred_rew]),np.sum([p == 1 for p in pred_rew]),np.sum([p == 2 for p in pred_rew])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_sub = [2 if y==-1 else y for y in y_test_sub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6483, 191, 1603)"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([p == 0 for p in y_test_sub]),np.sum([p == 1 for p in y_test_sub]),np.sum([p == 2 for p in y_test_sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1866, 2020, 2597],\n",
       "       [  16,  143,   32],\n",
       "       [ 273,  233, 1097]])"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_sub, y_pred_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6479,    0,    4],\n",
       "       [ 191,    0,    0],\n",
       "       [1595,    0,    8]])"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_sub, pred_rew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "y_test_bin = label_binarize(y_test_sub, classes=[0, 1, 2])\n",
    "y_pred_forest_bin = label_binarize(y_pred_forest, classes=[0, 1, 2]) #pred_rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision score, micro-averaged over all classes: 0.35\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# For each class\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(3):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_test_bin[:, i],\n",
    "                                                        y_pred_forest_bin[:, i])\n",
    "    average_precision[i] = average_precision_score(y_test_bin[:, i], y_pred_forest_bin[:, i])\n",
    "\n",
    "# A \"micro-average\": quantifying score on all classes jointly\n",
    "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_test_bin.ravel(),\n",
    "    y_pred_forest_bin.ravel())\n",
    "average_precision[\"micro\"] = average_precision_score(y_test_bin, y_pred_forest_bin,\n",
    "                                                     average=\"micro\")\n",
    "print('Average precision score, micro-averaged over all classes: {0:0.2f}'\n",
    "      .format(average_precision[\"micro\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Other',\n",
       " 'Injury And Poisoning',\n",
       " 'Neoplasms',\n",
       " 'Infectious And Parasitic Diseases',\n",
       " 'Diseases Of The Digestive System',\n",
       " 'Diseases Of The Circulatory System',\n",
       " 'Endocrine, Nutritional And Metabolic Diseases, And Immunity Disorders',\n",
       " 'Diseases Of The Respiratory System',\n",
       " 'Diseases Of The Musculoskeletal System And Connective Tissue',\n",
       " 'Diseases Of The Genitourinary System',\n",
       " 'Diseases Of The Skin And Subcutaneous Tissue',\n",
       " 'Mental Disorders',\n",
       " 'Diseases Of The Nervous System And Sense Organs',\n",
       " 'Congenital Anomalies',\n",
       " 'Diseases Of The Blood And Blood-Forming Organs',\n",
       " 'Symptoms, Signs, And Ill-Defined Conditions']"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df2['ICD9_CODE_CAT'].unique().tolist()\n",
    "a.remove('Complications Of Pregnancy, Childbirth, And The Puerperium')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other\n",
      "1    232\n",
      "0    216\n",
      "Name: gender__M, dtype: int64\n",
      "206.10642709053212\n",
      "247.0355871886121\n",
      "Injury And Poisoning\n",
      "1    1732\n",
      "0    1228\n",
      "Name: gender__M, dtype: int64\n",
      "1538.6910850034553\n",
      "1404.4430604982206\n",
      "Neoplasms\n",
      "1    809\n",
      "0    683\n",
      "Name: gender__M, dtype: int64\n",
      "718.7073255010366\n",
      "781.1356761565837\n",
      "Infectious And Parasitic Diseases\n",
      "1    760\n",
      "0    664\n",
      "Name: gender__M, dtype: int64\n",
      "675.1762266758811\n",
      "759.4056939501779\n",
      "Diseases Of The Digestive System\n",
      "1    996\n",
      "0    840\n",
      "Name: gender__M, dtype: int64\n",
      "884.8362128541811\n",
      "960.693950177936\n",
      "Diseases Of The Circulatory System\n",
      "1    3896\n",
      "0    2599\n",
      "Name: gender__M, dtype: int64\n",
      "3461.1665514858328\n",
      "2972.4328291814945\n",
      "Endocrine, Nutritional And Metabolic Diseases, And Immunity Disorders\n",
      "0    235\n",
      "1    233\n",
      "Name: gender__M, dtype: int64\n",
      "206.9948168624741\n",
      "268.7655693950178\n",
      "Diseases Of The Respiratory System\n",
      "0    630\n",
      "1    599\n",
      "Name: gender__M, dtype: int64\n",
      "532.1454733932273\n",
      "720.520462633452\n",
      "Diseases Of The Musculoskeletal System And Connective Tissue\n",
      "0    139\n",
      "1    123\n",
      "Name: gender__M, dtype: int64\n",
      "109.2719419488597\n",
      "158.97197508896798\n",
      "Diseases Of The Genitourinary System\n",
      "0    180\n",
      "1    172\n",
      "Name: gender__M, dtype: int64\n",
      "152.80304077401522\n",
      "205.8629893238434\n",
      "Diseases Of The Skin And Subcutaneous Tissue\n",
      "1    38\n",
      "0    26\n",
      "Name: gender__M, dtype: int64\n",
      "33.75881133379406\n",
      "29.73576512455516\n",
      "Mental Disorders\n",
      "1    174\n",
      "0     53\n",
      "Name: gender__M, dtype: int64\n",
      "154.57982031789908\n",
      "60.61521352313167\n",
      "Diseases Of The Nervous System And Sense Organs\n",
      "1    206\n",
      "0    167\n",
      "Name: gender__M, dtype: int64\n",
      "183.00829302004146\n",
      "190.99510676156584\n",
      "Congenital Anomalies\n",
      "1    54\n",
      "0    43\n",
      "Name: gender__M, dtype: int64\n",
      "47.973047684865236\n",
      "49.17838078291815\n",
      "Diseases Of The Blood And Blood-Forming Organs\n",
      "0    45\n",
      "1    35\n",
      "Name: gender__M, dtype: int64\n",
      "31.09364201796821\n",
      "51.46574733096085\n",
      "Symptoms, Signs, And Ill-Defined Conditions\n",
      "1    70\n",
      "0    64\n",
      "Name: gender__M, dtype: int64\n",
      "62.18728403593642\n",
      "73.19572953736655\n"
     ]
    }
   ],
   "source": [
    "for cat in a:\n",
    "    print(cat)\n",
    "    print(df2[df2['ICD9_CODE_CAT']==cat]['gender__M'].value_counts())\n",
    "    print(df2[df2['ICD9_CODE_CAT']==cat]['gender__M'].value_counts()[1]/df2['gender__M'].value_counts()[1]*df2['gender__M'].value_counts().sum()/2)\n",
    "    print(df2[df2['ICD9_CODE_CAT']==cat]['gender__M'].value_counts()[0]/df2['gender__M'].value_counts()[0]*df2['gender__M'].value_counts().sum()/2)\n",
    "    #     print(df2[df2['ICD9_CODE_CAT']==cat]['gender__M'].value_counts())\n",
    "    \n",
    "#ISSUE: More men than women in the dataset -> use proportions or use numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = []\n",
    "for a in df2['age']:\n",
    "    if a > 89:\n",
    "        ages.append(90)\n",
    "    else:\n",
    "        ages.append(a)\n",
    "        \n",
    "ecdf = ECDF(ages)\n",
    "\n",
    "age_cmf = {ecdf(a):a for a in range(np.max(ages)+1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_age(age_cmf):\n",
    "    draw_unif = np.random.uniform()\n",
    "    \n",
    "    key = -1\n",
    "    for k in age_cmf.keys():\n",
    "        if draw_unif > k:\n",
    "            key = k\n",
    "    draw = age_cmf[key]+1\n",
    "    \n",
    "    return(draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keyvanamini/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "codes = df2[df2['age_group__40-64']==0][df2['age_group__65-89']==0][df2['age_group__>89']==0]['ICD9_CODE_CAT']\n",
    "codes = [str(c) for c in codes]\n",
    "ecdf_condition_40 = ECDF(codes)\n",
    "condition_40_cmf = {ecdf_condition_40(a):a for a in codes}\n",
    "od_40 = collections.OrderedDict(sorted(condition_40_cmf.items()))\n",
    "\n",
    "codes = df2[df2['age_group__40-64']==1]['ICD9_CODE_CAT']\n",
    "codes = [str(c) for c in codes]\n",
    "ecdf_condition_40_64 = ECDF(codes)\n",
    "condition_40_64_cmf = {ecdf_condition_40_64(a):a for a in codes}\n",
    "od_40_64 = collections.OrderedDict(sorted(condition_40_64_cmf.items()))\n",
    "\n",
    "codes = df2[df2['age_group__65-89']==1]['ICD9_CODE_CAT']\n",
    "codes = [str(c) for c in codes]\n",
    "ecdf_condition_65_89 = ECDF(codes)\n",
    "condition_65_89_cmf = {ecdf_condition_65_89(a):a for a in codes}\n",
    "od_65_89 = collections.OrderedDict(sorted(condition_65_89_cmf.items()))\n",
    "\n",
    "codes = df2[df2['age_group__>89']==1]['ICD9_CODE_CAT']\n",
    "codes = [str(c) for c in codes]\n",
    "ecdf_condition_89 = ECDF(codes)\n",
    "condition_89_cmf = {ecdf_condition_89(a):a for a in codes}\n",
    "od_89 = collections.OrderedDict(sorted(condition_89_cmf.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def draw_condition_40():\n",
    "    draw_unif = np.random.uniform()\n",
    "    \n",
    "    diffs = {c:a-b for a,c,b in zip(list(od_40.keys()),list(od_40.values()),[draw_unif]*len(list(od_40.keys()))) if (a-b)>0}\n",
    "    draw = list(diffs.keys())[0]\n",
    "    \n",
    "    return(draw)\n",
    "\n",
    "def draw_condition_40_64():\n",
    "    draw_unif = np.random.uniform()\n",
    "    \n",
    "    diffs = {c:a-b for a,c,b in zip(list(od_40_64.keys()),list(od_40_64.values()),[draw_unif]*len(list(od_40_64.keys()))) if (a-b)>0}\n",
    "    draw = list(diffs.keys())[0]\n",
    "    \n",
    "    return(draw)\n",
    "\n",
    "def draw_condition_65_89():\n",
    "    draw_unif = np.random.uniform()\n",
    "    \n",
    "    diffs = {c:a-b for a,c,b in zip(list(od_65_89.keys()),list(od_65_89.values()),[draw_unif]*len(list(od_65_89.keys()))) if (a-b)>0}\n",
    "    draw = list(diffs.keys())[0]\n",
    "    \n",
    "    return(draw)\n",
    "\n",
    "def draw_condition_89():\n",
    "    draw_unif = np.random.uniform()\n",
    "    \n",
    "    diffs = {c:a-b for a,c,b in zip(list(od_89.keys()),list(od_89.values()),[draw_unif]*len(list(od_89.keys()))) if (a-b)>0}\n",
    "    draw = list(diffs.keys())[0]\n",
    "    \n",
    "    return(draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_agents1(n):\n",
    "    age = []\n",
    "    age_group = []\n",
    "    condition = []\n",
    "    gender_M = []\n",
    "\n",
    "    for i in range(n):\n",
    "        age.append(draw_age(age_cmf))\n",
    "        if age[i] < 40:\n",
    "            condition.append(draw_condition_40(od_40))\n",
    "            age_group.append(1)\n",
    "        elif age[i] <= 64: #& age[i] >= 40:\n",
    "            condition.append(draw_condition_40_64(od_40_64))\n",
    "            age_group.append(2)\n",
    "        elif age[i] <= 89: #age[i] > 64 & age[i] <= 89:\n",
    "            condition.append(draw_condition_65_89(od_65_89))\n",
    "            age_group.append(3)\n",
    "        else:\n",
    "            condition.append(draw_condition_89(od_89))\n",
    "            age_group.append(4)\n",
    "        \n",
    "        # Gender conditioned on some conditions\n",
    "        if condition[i] == 'Complications Of Pregnancy, Childbirth, And The Puerperium':\n",
    "            gender_M.append(0)\n",
    "        elif condition[i] == 'Injury And Poisoning':\n",
    "            counts = df2[df2['ICD9_CODE_CAT']=='Injury And Poisoning']['gender__M'].value_counts()\n",
    "            gender_M.append(np.random.binomial(1,counts[1]/counts.sum()))\n",
    "        elif condition[i] == 'Diseases Of The Circulatory System':\n",
    "            counts = df2[df2['ICD9_CODE_CAT']=='Diseases Of The Circulatory System']['gender__M'].value_counts()\n",
    "            gender_M.append(np.random.binomial(1,counts[1]/counts.sum()))\n",
    "        elif condition[i] == 'Mental Disorders':\n",
    "            counts = df2[df2['ICD9_CODE_CAT']=='Mental Disorders']['gender__M'].value_counts()\n",
    "            gender_M.append(np.random.binomial(1,counts[1]/counts.sum()))\n",
    "        else:\n",
    "            gender_M.append(np.random.binomial(1,0.5))\n",
    "    \n",
    "    return(age,age_group,condition,gender_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age,age_group,condition,gender_M = draw_agents(1000)\n",
    "# draw_ac = pd.DataFrame()\n",
    "# draw_ac['age'] = age\n",
    "# draw_ac['age_group'] = age_group\n",
    "# draw_ac['ICD9_CODE_CAT'] = condition\n",
    "# draw_ac['gender__M'] = gender_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age_groups = pd.get_dummies(draw_ac['age_group'],prefix='age_group_',drop_first=True)\n",
    "# age_groups.columns = ['age_group__40-64', 'age_group__65-89', 'age_group__>89']\n",
    "# draw_ac = pd.concat([draw_ac,age_groups],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICD9_CODE_CAT_binary = diagnosis_encoder.transform(draw_ac['ICD9_CODE_CAT'])\n",
    "# draw_ac2 = pd.concat([draw_ac,ICD9_CODE_CAT_binary],axis=1).drop(['ICD9_CODE_CAT','age','age_group'],axis=1)\n",
    "# draw_ac2 = pd.concat([draw_ac['age'],draw_ac2],axis=1)\n",
    "# knn_cols = [c for c in draw_ac2.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df3[df3['days_since_admission']==0]\n",
    "\n",
    "df5 = df5.drop(['days_since_admission','HOSPITAL_EXPIRE_FLAG','hospital_expire_flag','subject_id', 'hadm_id',\n",
    "               'ICUSTAY_ID', 'SUBJECT_ID', 'HADM_ID', 'INTIME', 'OUTTIME', 'DIFF',\n",
    "               'LAST_WARDID', 'GENDER','DOB', 'ICD9_CODE', 'SHORT_TITLE',\n",
    "               'LONG_TITLE', 'SEQ_NUM', 'DEATHTIME','ICUSTAY_AGE_GROUP',\n",
    "               'ICD9_CODE_CAT','date',\n",
    "               'INTIME_ACTUAL', 'OUTTIME_ACTUAL',\"CURR_CAREUNIT\",\"INSURANCE\",\"ADMISSION_TYPE\",\"DATE\",\"LOS\"],axis=1) #\n",
    "df5_index = df5.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare variables for model\n",
    "y_train=df5['out_flag']\n",
    "X_train=df5.drop(['out_flag'],axis=1)\n",
    "\n",
    "### Need to split train-test?\n",
    "# Split data in train and test\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_index = X_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "imp_iter = IterativeImputer(random_state=0)\n",
    "imp_iter.fit(X_train)\n",
    "X_train = imp_iter.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_train.columns = df5.drop(['out_flag'],axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.index = orig_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                       0\n",
       "DEATHRATE_CAT__1.0        0\n",
       "DEATHRATE_CAT__2.0        0\n",
       "DEATHRATE_INT_CAT__1.0    0\n",
       "DEATHRATE_INT_CAT__2.0    0\n",
       "                         ..\n",
       "ICD9_CODE_CAT_5           0\n",
       "caretime_doctors          0\n",
       "caretime_nurses           0\n",
       "cum_caretime_doctors      0\n",
       "cum_caretime_nurses       0\n",
       "Length: 68, dtype: int64"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['age'] = [90 if a>89 else a for a in X_train['age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sample_matches(X_train, knn_cols, draw_ac2):\n",
    "\n",
    "    filt = X_train[knn_cols]\n",
    "    sim = []\n",
    "    sim2 = []\n",
    "    sim2_df = pd.DataFrame(columns=X_train.columns)\n",
    "    ages = []\n",
    "\n",
    "    for j in range(draw_ac2.shape[0]):\n",
    "        \n",
    "        age = draw_ac2.loc[j,'age']\n",
    "        selected = [i for i in filt[filt['gender__M']==draw_ac2.loc[j,'gender__M']].index] #Initialize with gender\n",
    "        temp = []\n",
    "        for col in knn_cols[1:]:\n",
    "            temp = [i for i in filt[filt[col]==draw_ac2.loc[j,col]].index]\n",
    "            new = list(set(selected) & set(temp))\n",
    "            selected = np.copy(new)\n",
    "        \n",
    "            \n",
    "        if len(selected) >= 10:\n",
    "            sim.append(random.sample(list(selected),1)[0])\n",
    "            ages.append(age)\n",
    "        else:\n",
    "            print('less than 10')\n",
    "            sim2 = random.sample(list(selected),1)[0]\n",
    "            sim2_df = pd.concat([sim2_df, X_train.loc[[sim2]]])\n",
    "            mean_cols = ['gcs', 'heartrate', \n",
    "                'meanbp', 'resprate', 'temp', 'urineoutput','respiration','coagulation', 'liver',\n",
    "               'cardiovascular', 'cns', 'renal', 'HeartRate_Min', 'HeartRate_Max',\n",
    "               'HeartRate_Mean', 'SysBP_Min', 'SysBP_Max', 'SysBP_Mean', 'DiasBP_Min',\n",
    "               'DiasBP_Max', 'DiasBP_Mean', 'MeanBP_Min', 'MeanBP_Max', 'MeanBP_Mean',\n",
    "               'RespRate_Min', 'RespRate_Max', 'RespRate_Mean', 'TempC_Min',\n",
    "               'TempC_Max', 'TempC_Mean', 'SpO2_Min', 'SpO2_Max', 'SpO2_Mean',\n",
    "               'Glucose_Min', 'Glucose_Max', 'Glucose_Mean']\n",
    "            sim_mean = pd.DataFrame(X_train.loc[selected, mean_cols].mean()).transpose()\n",
    "            for i in mean_cols:\n",
    "                sim2_df.loc[sim2,i] = sim_mean[i][0]\n",
    "            sim2_df.loc[sim2,'age'] = age\n",
    "\n",
    "    sim1_df = X_train.loc[sim,]\n",
    "    sim1_df['age'] = ages\n",
    "    full_sim = pd.concat([sim2_df,sim1_df])\n",
    "    return(full_sim,sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# full_sim,sim = sample_matches(X_train, knn_cols, draw_ac2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# full_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import collections\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_age_cmf(df2):\n",
    "    ages = []\n",
    "    for a in df2['age']:\n",
    "        if a > 89:\n",
    "            ages.append(90)\n",
    "        else:\n",
    "            ages.append(a)\n",
    "\n",
    "    ecdf = ECDF(ages)\n",
    "\n",
    "    age_cmf = {ecdf(a):a for a in range(np.max(ages)+1)}\n",
    "    return(age_cmf)\n",
    "\n",
    "def draw_age(age_cmf):\n",
    "    \n",
    "    draw_unif = np.random.uniform()\n",
    "    \n",
    "    key = -1\n",
    "    for k in age_cmf.keys():\n",
    "        if draw_unif > k:\n",
    "            key = k\n",
    "    draw = age_cmf[key]+1\n",
    "    \n",
    "    return(draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_ods (df2):\n",
    "    codes = df2[df2['age_group__40-64']==0][df2['age_group__65-89']==0][df2['age_group__>89']==0]['ICD9_CODE_CAT']\n",
    "    codes = [str(c) for c in codes]\n",
    "    ecdf_condition_40 = ECDF(codes)\n",
    "    condition_40_cmf = {ecdf_condition_40(a):a for a in codes}\n",
    "    od_40 = collections.OrderedDict(sorted(condition_40_cmf.items()))\n",
    "\n",
    "    codes = df2[df2['age_group__40-64']==1]['ICD9_CODE_CAT']\n",
    "    codes = [str(c) for c in codes]\n",
    "    ecdf_condition_40_64 = ECDF(codes)\n",
    "    condition_40_64_cmf = {ecdf_condition_40_64(a):a for a in codes}\n",
    "    od_40_64 = collections.OrderedDict(sorted(condition_40_64_cmf.items()))\n",
    "\n",
    "    codes = df2[df2['age_group__65-89']==1]['ICD9_CODE_CAT']\n",
    "    codes = [str(c) for c in codes]\n",
    "    ecdf_condition_65_89 = ECDF(codes)\n",
    "    condition_65_89_cmf = {ecdf_condition_65_89(a):a for a in codes}\n",
    "    od_65_89 = collections.OrderedDict(sorted(condition_65_89_cmf.items()))\n",
    "\n",
    "    codes = df2[df2['age_group__>89']==1]['ICD9_CODE_CAT']\n",
    "    codes = [str(c) for c in codes]\n",
    "    ecdf_condition_89 = ECDF(codes)\n",
    "    condition_89_cmf = {ecdf_condition_89(a):a for a in codes}\n",
    "    od_89 = collections.OrderedDict(sorted(condition_89_cmf.items()))\n",
    "    \n",
    "    return(od_40,od_40_64,od_65_89,od_89)\n",
    "\n",
    "def draw_condition_40(od_40):\n",
    "    draw_unif = np.random.uniform()\n",
    "    \n",
    "    diffs = {c:a-b for a,c,b in zip(list(od_40.keys()),list(od_40.values()),[draw_unif]*len(list(od_40.keys()))) if (a-b)>0}\n",
    "    draw = list(diffs.keys())[0]\n",
    "    \n",
    "    return(draw)\n",
    "\n",
    "def draw_condition_40_64(od_40_64):\n",
    "    draw_unif = np.random.uniform()\n",
    "    \n",
    "    diffs = {c:a-b for a,c,b in zip(list(od_40_64.keys()),list(od_40_64.values()),[draw_unif]*len(list(od_40_64.keys()))) if (a-b)>0}\n",
    "    draw = list(diffs.keys())[0]\n",
    "    \n",
    "    return(draw)\n",
    "\n",
    "def draw_condition_65_89(od_65_89):\n",
    "    draw_unif = np.random.uniform()\n",
    "    \n",
    "    diffs = {c:a-b for a,c,b in zip(list(od_65_89.keys()),list(od_65_89.values()),[draw_unif]*len(list(od_65_89.keys()))) if (a-b)>0}\n",
    "    draw = list(diffs.keys())[0]\n",
    "    \n",
    "    return(draw)\n",
    "\n",
    "def draw_condition_89(od_89):\n",
    "    draw_unif = np.random.uniform()\n",
    "    \n",
    "    diffs = {c:a-b for a,c,b in zip(list(od_89.keys()),list(od_89.values()),[draw_unif]*len(list(od_89.keys()))) if (a-b)>0}\n",
    "    draw = list(diffs.keys())[0]\n",
    "    \n",
    "    return(draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_agents(n, df2, age_cmf,od_40,od_40_64,od_65_89,od_89):\n",
    "    age = []\n",
    "    age_group = []\n",
    "    condition = []\n",
    "    gender_M = []\n",
    "\n",
    "    for i in range(n):\n",
    "        age.append(draw_age(age_cmf))\n",
    "        if age[i] < 40:\n",
    "            condition.append(draw_condition_40(od_40))\n",
    "            age_group.append(1)\n",
    "        elif age[i] <= 64: \n",
    "            condition.append(draw_condition_40_64(od_40_64))\n",
    "            age_group.append(2)\n",
    "        elif age[i] <= 89:\n",
    "            condition.append(draw_condition_65_89(od_65_89))\n",
    "            age_group.append(3)\n",
    "        else:\n",
    "            condition.append(draw_condition_89(od_89))\n",
    "            age_group.append(4)\n",
    "        \n",
    "        # Gender conditioned on some conditions\n",
    "        if condition[i] == 'Complications Of Pregnancy, Childbirth, And The Puerperium':\n",
    "            gender_M.append(0)\n",
    "        elif condition[i] == 'Injury And Poisoning':\n",
    "            counts = df2[df2['ICD9_CODE_CAT']=='Injury And Poisoning']['gender__M'].value_counts()\n",
    "            gender_M.append(np.random.binomial(1,counts[1]/counts.sum()))\n",
    "        elif condition[i] == 'Diseases Of The Circulatory System':\n",
    "            counts = df2[df2['ICD9_CODE_CAT']=='Diseases Of The Circulatory System']['gender__M'].value_counts()\n",
    "            gender_M.append(np.random.binomial(1,counts[1]/counts.sum()))\n",
    "        elif condition[i] == 'Mental Disorders':\n",
    "            counts = df2[df2['ICD9_CODE_CAT']=='Mental Disorders']['gender__M'].value_counts()\n",
    "            gender_M.append(np.random.binomial(1,counts[1]/counts.sum()))\n",
    "        else:\n",
    "            gender_M.append(np.random.binomial(1,0.5))\n",
    "    \n",
    "    draw_acg = pd.DataFrame()\n",
    "    draw_acg['age'] = age\n",
    "    draw_acg['age_group'] = age_group\n",
    "    draw_acg['ICD9_CODE_CAT'] = condition\n",
    "    draw_acg['gender__M'] = gender_M\n",
    "    \n",
    "    age_groups = pd.get_dummies(draw_acg['age_group'],prefix='age_group_',drop_first=True)\n",
    "    age_groups = age_groups.rename(columns={\"age_group__2\": \"age_group__40-64\", \"age_group__3\": \"age_group__65-89\", \"age_group__4\": \"age_group__>89\"})\n",
    "    draw_acg = pd.concat([draw_acg,age_groups],axis=1)\n",
    "    \n",
    "    return(draw_acg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_train (df3):\n",
    "    df5 = df3[df3['days_since_admission']==0]\n",
    "\n",
    "    df5 = df5.drop(['days_since_admission','HOSPITAL_EXPIRE_FLAG','hospital_expire_flag','subject_id', 'hadm_id',\n",
    "                   'ICUSTAY_ID', 'SUBJECT_ID', 'HADM_ID', 'INTIME', 'OUTTIME', 'DIFF',\n",
    "                   'LAST_WARDID', 'GENDER','DOB', 'ICD9_CODE', 'SHORT_TITLE',\n",
    "                   'LONG_TITLE', 'SEQ_NUM', 'DEATHTIME','ICUSTAY_AGE_GROUP',\n",
    "                   'ICD9_CODE_CAT','date',\n",
    "                   'INTIME_ACTUAL', 'OUTTIME_ACTUAL',\"CURR_CAREUNIT\",\"INSURANCE\",\"ADMISSION_TYPE\",\"DATE\",\"LOS\",\n",
    "#                    'COUNT_DOCTORS', 'COUNT_NURSES', 'COUNT_PATIENTS',\n",
    "                   'cum_caretime_doctors','cum_caretime_nurses'],axis=1)\n",
    "\n",
    "    y_train=df5['out_flag']\n",
    "    X_train=df5.drop(['out_flag'],axis=1)\n",
    "\n",
    "    imp_iter = IterativeImputer(random_state=0)\n",
    "    imp_iter.fit(X_train)\n",
    "    X_train = imp_iter.transform(X_train)\n",
    "\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_train.columns = df5.drop(['out_flag'],axis=1).columns\n",
    "\n",
    "    X_train['age'] = [90 if a>89 else a for a in X_train['age']]\n",
    "        \n",
    "    return(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_age (df, index, new_age):\n",
    "    df.loc[index,\"age_group__>89\"] = 0\n",
    "    df.loc[index,\"age_group__65-89\"] = 0\n",
    "    df.loc[index,\"age_group__40-64\"] = 0\n",
    "\n",
    "    if new_age > 89:\n",
    "        df.loc[index,\"age_group__>89\"] = 1\n",
    "    elif new_age >= 65:\n",
    "        df.loc[index,\"age_group__65-89\"] = 1\n",
    "    elif new_age >= 40:\n",
    "        df.loc[index,\"age_group__40-64\"] = 1\n",
    "        \n",
    "#             draw_acg2.loc[j,\"age_group__>89\"] = 0\n",
    "#             draw_acg2.loc[j,\"age_group__65-89\"] = 0\n",
    "#             draw_acg2.loc[j,\"age_group__40-64\"] = 0\n",
    "            \n",
    "#             if age_up > 89:\n",
    "#                 draw_acg2.loc[j,\"age_group__>89\"] = 1\n",
    "#             elif age_up >= 65:\n",
    "#                 draw_acg2.loc[j,\"age_group__65-89\"] = 1\n",
    "#             elif age_up >= 40:\n",
    "#                 draw_acg2.loc[j,\"age_group__40-64\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_matches(X_train, knn_cols, draw_acg2):\n",
    "\n",
    "    filt = X_train[knn_cols]\n",
    "    sim = []\n",
    "    sim2 = []\n",
    "    sim2_df = pd.DataFrame(columns=X_train.columns)\n",
    "    ages = []\n",
    "\n",
    "    for j in range(draw_acg2.shape[0]):\n",
    "        \n",
    "        age = draw_acg2.loc[j,'age']\n",
    "        selected = [i for i in filt[filt['gender__M']==draw_acg2.loc[j,'gender__M']].index] #Initialize with gender\n",
    "        temp = []\n",
    "        for col in knn_cols[1:]:\n",
    "            temp = [i for i in filt[filt[col]==draw_acg2.loc[j,col]].index]\n",
    "            new = list(set(selected) & set(temp))\n",
    "            selected = np.copy(new)\n",
    "        \n",
    "        if len(selected) >= 10:\n",
    "            sim.append(random.sample(list(selected),1)[0])\n",
    "            ages.append(age)\n",
    "        elif len(selected) == 0:\n",
    "            print('no match')\n",
    "        else:\n",
    "            print('less than 10')\n",
    "            sim2 = random.sample(list(selected),1)[0]\n",
    "            sim2_df = pd.concat([sim2_df, X_train.loc[[sim2]]])\n",
    "            mean_cols = ['gcs', 'heartrate', \n",
    "                'meanbp', 'resprate', 'temp', 'urineoutput','respiration','coagulation', 'liver',\n",
    "               'cardiovascular', 'cns', 'renal', 'HeartRate_Min', 'HeartRate_Max',\n",
    "               'HeartRate_Mean', 'SysBP_Min', 'SysBP_Max', 'SysBP_Mean', 'DiasBP_Min',\n",
    "               'DiasBP_Max', 'DiasBP_Mean', 'MeanBP_Min', 'MeanBP_Max', 'MeanBP_Mean',\n",
    "               'RespRate_Min', 'RespRate_Max', 'RespRate_Mean', 'TempC_Min',\n",
    "               'TempC_Max', 'TempC_Mean', 'SpO2_Min', 'SpO2_Max', 'SpO2_Mean',\n",
    "               'Glucose_Min', 'Glucose_Max', 'Glucose_Mean']\n",
    "            \n",
    "            sim_mean = pd.DataFrame(X_train.loc[selected, mean_cols].mean()).transpose()\n",
    "            \n",
    "            age_up = age + 25\n",
    "            encode_age (draw_acg2, j, age_up)\n",
    "    \n",
    "            selected_up = [i for i in filt[filt['gender__M']==draw_acg2.loc[j,'gender__M']].index] #Initialize with gender\n",
    "            temp = []\n",
    "            for col in knn_cols[1:]:\n",
    "                temp = [i for i in filt[filt[col]==draw_acg2.loc[j,col]].index]\n",
    "                new = list(set(selected_up) & set(temp))\n",
    "                selected_up = np.copy(new)\n",
    "\n",
    "            age_down = age - 25\n",
    "            encode_age (draw_acg2, j, age_down)\n",
    "            \n",
    "            selected_down = [i for i in filt[filt['gender__M']==draw_acg2.loc[j,'gender__M']].index] #Initialize with gender\n",
    "            temp = []\n",
    "            for col in knn_cols[1:]:\n",
    "                temp = [i for i in filt[filt[col]==draw_acg2.loc[j,col]].index]\n",
    "                new = list(set(selected_down) & set(temp))\n",
    "                selected_down = np.copy(new)\n",
    "            \n",
    "            selected = selected.tolist()\n",
    "            selected.extend(selected_up)\n",
    "            selected.extend(selected_down)\n",
    "            \n",
    "            selected_exp = list(set(selected))\n",
    "\n",
    "            sim_sd = pd.DataFrame(X_train.loc[selected_exp, mean_cols].std()).transpose()\n",
    "                        \n",
    "            for i in mean_cols:\n",
    "                sim2_df.loc[sim2,i] = np.random.normal(sim_mean[i][0], sim_sd[i][0])\n",
    "            sim2_df.loc[sim2,'age'] = age\n",
    "\n",
    "    sim1_df = X_train.loc[sim,]\n",
    "    sim1_df['age'] = ages\n",
    "    full_sim = pd.concat([sim2_df,sim1_df])\n",
    "    return(full_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hundred_sim(df6,df3,col_ord,full_sim):\n",
    "    df6 = df6.loc[:,['ICUSTAY_ID']+col_ord]\n",
    "    pat_rec = df6[df6['ICUSTAY_ID']==df3.loc[full_sim.index[0],:]['ICUSTAY_ID']]\n",
    "    daily = pat_rec[['days_since_admission','procedure_SignificantEvents','procedure_Ventilation']]\n",
    "    included = set([d for d in daily['days_since_admission']])\n",
    "    for i in range(1010):\n",
    "        if i not in included:\n",
    "            day = pd.DataFrame({'days_since_admission':[i],'procedure_SignificantEvents':[0],'procedure_Ventilation':[0]})\n",
    "            daily = pd.concat([daily,day],axis=0)\n",
    "    daily = daily.reset_index()\n",
    "    daily = daily.drop('index',axis=1)\n",
    "    newdf = pd.DataFrame(np.repeat(full_sim.values,110,axis=0))\n",
    "    newdf.columns = full_sim.columns\n",
    "    newdf = newdf.drop('days_since_admission',axis=1)\n",
    "    return(pd.concat([newdf,daily],axis=1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def simulate (n, df2, df3, df6, X_train, age_cmf, od_40,od_40_64,od_65_89,od_89, diagnosis_encoder, col_ord):\n",
    "\n",
    "    draw_acg = draw_agents(n, df2, age_cmf, od_40, od_40_64, od_65_89, od_89)\n",
    "    \n",
    "    ICD9_CODE_CAT_binary = diagnosis_encoder.transform(draw_acg['ICD9_CODE_CAT'])\n",
    "    draw_acg2 = pd.concat([draw_acg,ICD9_CODE_CAT_binary],axis=1).drop(['ICD9_CODE_CAT','age','age_group'],axis=1)\n",
    "    draw_acg2 = pd.concat([draw_acg['age'],draw_acg2],axis=1)\n",
    "    knn_cols = [c for c in draw_acg2.columns]\n",
    "    \n",
    "    full_sim = sample_matches(X_train, knn_cols, draw_acg2)\n",
    "    \n",
    "#     full_sim = full_sim.reset_index()\n",
    "#     full_sim = full_sim.drop('index',axis=1)\n",
    "    full_sim['days_since_admission'] = 0\n",
    "    \n",
    "    col_order = [f for f in col_ord if f not in ['procedure_SignificantEvents','procedure_Ventilation','cum_caretime_doctors','cum_caretime_nurses']]\n",
    "    full_sim = full_sim[col_order]\n",
    "    \n",
    "    out = hundred_sim(df6,df3,col_ord,full_sim)\n",
    "    \n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keyvanamini/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "age_cmf = prep_age_cmf(df2)\n",
    "od_40,od_40_64,od_65_89,od_89 = prep_ods(df2)\n",
    "X_train, y_train = prep_train(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_full = simulate(1, df2, df3, df6, X_train, age_cmf, od_40,od_40_64,od_65_89,od_89, diagnosis_encoder,col_ord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>preiculos</th>\n",
       "      <th>gcs</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>meanbp</th>\n",
       "      <th>resprate</th>\n",
       "      <th>temp</th>\n",
       "      <th>urineoutput</th>\n",
       "      <th>respiration</th>\n",
       "      <th>coagulation</th>\n",
       "      <th>...</th>\n",
       "      <th>careunit__TSICU</th>\n",
       "      <th>ICD9_CODE_CAT_0</th>\n",
       "      <th>ICD9_CODE_CAT_1</th>\n",
       "      <th>ICD9_CODE_CAT_2</th>\n",
       "      <th>ICD9_CODE_CAT_3</th>\n",
       "      <th>ICD9_CODE_CAT_4</th>\n",
       "      <th>ICD9_CODE_CAT_5</th>\n",
       "      <th>days_since_admission</th>\n",
       "      <th>procedure_SignificantEvents</th>\n",
       "      <th>procedure_Ventilation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>76</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>35.5556</td>\n",
       "      <td>3097</td>\n",
       "      <td>0.711371</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>76</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>35.5556</td>\n",
       "      <td>3097</td>\n",
       "      <td>0.711371</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>76</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>35.5556</td>\n",
       "      <td>3097</td>\n",
       "      <td>0.711371</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>76</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>35.5556</td>\n",
       "      <td>3097</td>\n",
       "      <td>0.711371</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>76</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>35.5556</td>\n",
       "      <td>3097</td>\n",
       "      <td>0.711371</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1010 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age preiculos  gcs heartrate meanbp resprate     temp urineoutput  \\\n",
       "0      70         0   15        76     58       10  35.5556        3097   \n",
       "1      70         0   15        76     58       10  35.5556        3097   \n",
       "2      70         0   15        76     58       10  35.5556        3097   \n",
       "3      70         0   15        76     58       10  35.5556        3097   \n",
       "4      70         0   15        76     58       10  35.5556        3097   \n",
       "...   ...       ...  ...       ...    ...      ...      ...         ...   \n",
       "1005  NaN       NaN  NaN       NaN    NaN      NaN      NaN         NaN   \n",
       "1006  NaN       NaN  NaN       NaN    NaN      NaN      NaN         NaN   \n",
       "1007  NaN       NaN  NaN       NaN    NaN      NaN      NaN         NaN   \n",
       "1008  NaN       NaN  NaN       NaN    NaN      NaN      NaN         NaN   \n",
       "1009  NaN       NaN  NaN       NaN    NaN      NaN      NaN         NaN   \n",
       "\n",
       "     respiration coagulation  ... careunit__TSICU ICD9_CODE_CAT_0  \\\n",
       "0       0.711371           0  ...               1               0   \n",
       "1       0.711371           0  ...               1               0   \n",
       "2       0.711371           0  ...               1               0   \n",
       "3       0.711371           0  ...               1               0   \n",
       "4       0.711371           0  ...               1               0   \n",
       "...          ...         ...  ...             ...             ...   \n",
       "1005         NaN         NaN  ...             NaN             NaN   \n",
       "1006         NaN         NaN  ...             NaN             NaN   \n",
       "1007         NaN         NaN  ...             NaN             NaN   \n",
       "1008         NaN         NaN  ...             NaN             NaN   \n",
       "1009         NaN         NaN  ...             NaN             NaN   \n",
       "\n",
       "     ICD9_CODE_CAT_1 ICD9_CODE_CAT_2 ICD9_CODE_CAT_3 ICD9_CODE_CAT_4  \\\n",
       "0                  0               0               0               1   \n",
       "1                  0               0               0               1   \n",
       "2                  0               0               0               1   \n",
       "3                  0               0               0               1   \n",
       "4                  0               0               0               1   \n",
       "...              ...             ...             ...             ...   \n",
       "1005             NaN             NaN             NaN             NaN   \n",
       "1006             NaN             NaN             NaN             NaN   \n",
       "1007             NaN             NaN             NaN             NaN   \n",
       "1008             NaN             NaN             NaN             NaN   \n",
       "1009             NaN             NaN             NaN             NaN   \n",
       "\n",
       "     ICD9_CODE_CAT_5 days_since_admission procedure_SignificantEvents  \\\n",
       "0                  0                    0                         0.0   \n",
       "1                  0                    1                         0.0   \n",
       "2                  0                    2                         0.0   \n",
       "3                  0                    3                         0.0   \n",
       "4                  0                    4                         0.0   \n",
       "...              ...                  ...                         ...   \n",
       "1005             NaN                 1005                         0.0   \n",
       "1006             NaN                 1006                         0.0   \n",
       "1007             NaN                 1007                         0.0   \n",
       "1008             NaN                 1008                         0.0   \n",
       "1009             NaN                 1009                         0.0   \n",
       "\n",
       "     procedure_Ventilation  \n",
       "0                      0.0  \n",
       "1                      0.0  \n",
       "2                      0.0  \n",
       "3                      0.0  \n",
       "4                      0.0  \n",
       "...                    ...  \n",
       "1005                   0.0  \n",
       "1006                   0.0  \n",
       "1007                   0.0  \n",
       "1008                   0.0  \n",
       "1009                   0.0  \n",
       "\n",
       "[1010 rows x 67 columns]"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'preiculos',\n",
       " 'gcs',\n",
       " 'heartrate',\n",
       " 'meanbp',\n",
       " 'resprate',\n",
       " 'temp',\n",
       " 'urineoutput',\n",
       " 'respiration',\n",
       " 'coagulation',\n",
       " 'liver',\n",
       " 'cardiovascular',\n",
       " 'cns',\n",
       " 'renal',\n",
       " 'HeartRate_Min',\n",
       " 'HeartRate_Max',\n",
       " 'HeartRate_Mean',\n",
       " 'SysBP_Min',\n",
       " 'SysBP_Max',\n",
       " 'SysBP_Mean',\n",
       " 'DiasBP_Min',\n",
       " 'DiasBP_Max',\n",
       " 'DiasBP_Mean',\n",
       " 'MeanBP_Min',\n",
       " 'MeanBP_Max',\n",
       " 'MeanBP_Mean',\n",
       " 'RespRate_Min',\n",
       " 'RespRate_Max',\n",
       " 'RespRate_Mean',\n",
       " 'TempC_Min',\n",
       " 'TempC_Max',\n",
       " 'TempC_Mean',\n",
       " 'SpO2_Min',\n",
       " 'SpO2_Max',\n",
       " 'SpO2_Mean',\n",
       " 'Glucose_Min',\n",
       " 'Glucose_Max',\n",
       " 'Glucose_Mean',\n",
       " 'DEATHRATE_CAT__1.0',\n",
       " 'DEATHRATE_CAT__2.0',\n",
       " 'DEATHRATE_INT_CAT__1.0',\n",
       " 'DEATHRATE_INT_CAT__2.0',\n",
       " 'mechvent',\n",
       " 'electivesurgery',\n",
       " 'gender__M',\n",
       " 'age_group__40-64',\n",
       " 'age_group__65-89',\n",
       " 'age_group__>89',\n",
       " 'ADMISSION_TYPE__EMERGENCY',\n",
       " 'ADMISSION_TYPE__URGENT',\n",
       " 'INSURANCE_TYPE__Medicaid',\n",
       " 'INSURANCE_TYPE__Medicare',\n",
       " 'INSURANCE_TYPE__Private',\n",
       " 'INSURANCE_TYPE__Self Pay',\n",
       " 'careunit__CSRU',\n",
       " 'careunit__MICU',\n",
       " 'careunit__SICU',\n",
       " 'careunit__TSICU',\n",
       " 'ICD9_CODE_CAT_0',\n",
       " 'ICD9_CODE_CAT_1',\n",
       " 'ICD9_CODE_CAT_2',\n",
       " 'ICD9_CODE_CAT_3',\n",
       " 'ICD9_CODE_CAT_4',\n",
       " 'ICD9_CODE_CAT_5',\n",
       " 'days_since_admission',\n",
       " 'procedure_SignificantEvents',\n",
       " 'procedure_Ventilation',\n",
       " 'cum_caretime_doctors',\n",
       " 'cum_caretime_nurses']"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_ord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>preiculos</th>\n",
       "      <th>gcs</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>meanbp</th>\n",
       "      <th>resprate</th>\n",
       "      <th>temp</th>\n",
       "      <th>urineoutput</th>\n",
       "      <th>respiration</th>\n",
       "      <th>coagulation</th>\n",
       "      <th>...</th>\n",
       "      <th>ICD9_CODE_CAT_1</th>\n",
       "      <th>ICD9_CODE_CAT_2</th>\n",
       "      <th>ICD9_CODE_CAT_3</th>\n",
       "      <th>ICD9_CODE_CAT_4</th>\n",
       "      <th>ICD9_CODE_CAT_5</th>\n",
       "      <th>days_since_admission</th>\n",
       "      <th>procedure_SignificantEvents</th>\n",
       "      <th>procedure_Ventilation</th>\n",
       "      <th>cum_caretime_doctors</th>\n",
       "      <th>cum_caretime_nurses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>76</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>35.5556</td>\n",
       "      <td>3097</td>\n",
       "      <td>0.711371</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age preiculos gcs heartrate meanbp resprate     temp urineoutput  \\\n",
       "10  70         0  15        76     58       10  35.5556        3097   \n",
       "\n",
       "   respiration coagulation  ... ICD9_CODE_CAT_1 ICD9_CODE_CAT_2  \\\n",
       "10    0.711371           0  ...               0               0   \n",
       "\n",
       "   ICD9_CODE_CAT_3 ICD9_CODE_CAT_4 ICD9_CODE_CAT_5 days_since_admission  \\\n",
       "10               0               1               0                   10   \n",
       "\n",
       "   procedure_SignificantEvents procedure_Ventilation cum_caretime_doctors  \\\n",
       "10                         0.0                   0.0                 0.01   \n",
       "\n",
       "   cum_caretime_nurses  \n",
       "10                   3  \n",
       "\n",
       "[1 rows x 69 columns]"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = z_full.loc[[10]]\n",
    "z['cum_caretime_doctors']=0.01\n",
    "z['cum_caretime_nurses']=3\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction_svm(z,False,q0,r0,q1,r1,q2,r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsRegressor, NearestNeighbors\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# nn = NearestNeighbors(n_neighbors=20)\n",
    "# nn.fit(X_train[knn_cols])\n",
    "# nn.kneighbors(draw_ac2) #returns distances, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABM MESA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age,age_group,condition,gender_M = draw_agents(10, df2, age_cmf, od_40, od_40_64, od_65_89, od_89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "intimes = df2[\"INTIME_ACTUAL\"].astype(\"datetime64\")\n",
    "intimes_count= intimes.groupby(intimes.dt.date).count()\n",
    "\n",
    "ecdf2 = ECDF(intimes_count)\n",
    "patient_inflow_cmf = {ecdf2(a):a for a in range(np.max(intimes_count)+1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the cdf\n",
    "plt.plot(ecdf2.x, ecdf2.y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_patient_inflow():\n",
    "    draw_unif = np.random.uniform()\n",
    "    \n",
    "    key = -1\n",
    "    for k in patient_inflow_cmf.keys():\n",
    "        if draw_unif > k:\n",
    "            key = k\n",
    "    draw = patient_inflow_cmf[key]+1\n",
    "    \n",
    "    return(draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 10, 13, 8, 15, 13, 10, 18, 9, 6]\n"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "for i in range(10):\n",
    "        temp.append(draw_patient_inflow())\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 10, 14, 5, 11, 14, 10, 9, 12, 10]\n"
     ]
    }
   ],
   "source": [
    "b = []\n",
    "for i in range(10):\n",
    "    b.append(draw_patient_inflow())\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location(x):\n",
    "    if x['careunit__CSRU'] == 1: return 'CSRU'\n",
    "    elif x['careunit__MICU'] == 1: return 'MICU'\n",
    "    elif x['careunit__SICU'] == 1: return 'SICU'\n",
    "    elif x['careunit__TSICU'] == 1: return 'TSICU'\n",
    "    else: return \"Other\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyActivation(BaseScheduler):\n",
    "\n",
    "    def step(self) -> None:\n",
    "        \"\"\" Executes the step of all agents, one at a time, in\n",
    "        random order.\n",
    "\n",
    "        \"\"\"\n",
    "        for agent in self.agent_buffer(shuffled=True):\n",
    "            agent.step()\n",
    "        self.steps += 1\n",
    "        self.time += 1\n",
    "        \n",
    "    def advance(self) -> None:\n",
    "        for agent in self.agent_buffer(shuffled=True):\n",
    "            agent.advance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatienFlowModel(Model):\n",
    "    '''Simple model for running models with a finite life'''\n",
    "    def __init__(self, n_agents=20, max_agents=50, n_doctors=3, n_nurses=250,service_level=1): #agent_LOS,\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_agents = n_agents\n",
    "        self.max_agents = max_agents\n",
    "        self.n_doctors = n_doctors\n",
    "        self.n_nurses = n_nurses\n",
    "        self.max_cap_by = 0\n",
    "        self.max_cap_daily = 0\n",
    "        self.service_level = service_level\n",
    "        self.caretime_doctors = 0\n",
    "        self.caretime_nurses = 0\n",
    "        self.count_discharges = 0\n",
    "        self.count_deaths = 0\n",
    "        self.demand_serviced = 0\n",
    "                \n",
    "        # keep track of the the remaining life of an agent and\n",
    "        # how many ticks it has seen\n",
    "        self.datacollector = DataCollector(model_reporters={\"agent_count\":lambda m: m.schedule.get_agent_count(),\n",
    "                                                           \"max_cap_by\":lambda m: m.max_cap_by,\n",
    "                                                           \"max_cap_daily\":lambda m: m.max_cap_daily,\n",
    "                                                           \"count_discharges\":lambda m: m.count_discharges,\n",
    "                                                           \"count_deaths\":lambda m: m.count_deaths,\n",
    "                                                           \"demand_serviced\":lambda m: m.demand_serviced},\n",
    "            agent_reporters={\"out_flag\": lambda a: a.out_flag,\n",
    "                             \"days_in_hospital\": lambda a: a.steps, # +1 Because if prediction of out_flag is 0 or -1, then LOS is 1 not 0\n",
    "                            \"info\": lambda a: a.info,\n",
    "                            \"NPI\": lambda a: a.NPI,\n",
    "                            \"Careunit\": lambda a: a.careunit,\n",
    "                            \"cum_caretime_doctors\": lambda a: a.caretime_doctors,\n",
    "                            \"cum_caretime_nurses\": lambda a: a.caretime_nurses}) \n",
    "\n",
    "        self.current_ID = 0\n",
    "        self.schedule = MyActivation(self)\n",
    "\n",
    "        for _ in range(self.n_agents):\n",
    "            # Set seed here\n",
    "            prior_steps = np.random.randint(low=1,high=4,size=1)[0] #Should be a random draw\n",
    "            self.schedule.add(PatienFlowAgent(self.next_id(),self,prior_steps))\n",
    "\n",
    "    def step(self):\n",
    "        '''Add agents back to n_agents in each step'''\n",
    "#         self.datacollector.collect(self)\n",
    "#         self.schedule.step()\n",
    "        \n",
    "        # Here we define how many new agents/patients are drawn from ECDF(based on empirical distribution from real data)\n",
    "        new_patients = draw_patient_inflow()\n",
    "\n",
    "        if len(self.schedule.agents) + new_patients <= round(self.service_level * self.max_agents):\n",
    "            for _ in range(new_patients):\n",
    "                self.schedule.add(PatienFlowAgent(self.next_id(),self))\n",
    "            self.max_cap_daily = 0\n",
    "        elif len(self.schedule.agents) < round(self.service_level * self.max_agents):\n",
    "            new_patients_2 = round(self.service_level * self.max_agents) - len(self.schedule.agents)\n",
    "            for _ in range(new_patients_2):\n",
    "                self.schedule.add(PatienFlowAgent(self.next_id(),self))    \n",
    "            self.max_cap_daily = new_patients - new_patients_2\n",
    "            self.max_cap_by += self.max_cap_daily\n",
    "        else:\n",
    "            self.max_cap_daily = new_patients\n",
    "            self.max_cap_by += self.max_cap_daily\n",
    "            \n",
    "        self.caretime_doctors = self.n_doctors/len(self.schedule.agents)\n",
    "        self.caretime_nurses = self.n_nurses/len(self.schedule.agents)\n",
    "        \n",
    "        self.schedule.step()\n",
    "        self.datacollector.collect(self)\n",
    "        self.schedule.advance()\n",
    "\n",
    "        self.demand_serviced = 1-self.max_cap_by/(len(self.schedule.agents)+self.max_cap_by+self.count_discharges+self.count_deaths)\n",
    "\n",
    "    def run_model(self, step_count=100):\n",
    "        for _ in range(step_count):\n",
    "            self.step()\n",
    "\n",
    "\n",
    "class PatienFlowAgent(Agent):\n",
    "    '''An agent that is supposed to live for a finite number of ticks.\n",
    "    Also has a 10% chance of dying in each tick.\n",
    "    '''\n",
    "    def __init__(self, unique_id, model, prior_steps=0): #LOS, \n",
    "        super().__init__(unique_id, model)\n",
    "        self.steps = prior_steps\n",
    "        self.model = model\n",
    "         # Simulation of new agents\n",
    "        self.info = simulate(1, df2, df3, df6, X_train, age_cmf, od_40,od_40_64,od_65_89,od_89, diagnosis_encoder, col_ord)\n",
    "        self.info['cum_caretime_doctors'] = 0\n",
    "        self.info['cum_caretime_nurses'] = 0\n",
    "        self.caretime_doctors = 0\n",
    "        self.caretime_nurses = 0\n",
    "        self.NPI = 3\n",
    "        self.careunit = self.info.apply(get_location, axis=1)[0]\n",
    "        self.out_flag = 0\n",
    "        \n",
    "    def step(self):\n",
    "            curr_info = self.info.loc[[self.steps]]\n",
    "            self.caretime_doctors += self.model.caretime_doctors\n",
    "            self.caretime_nurses  += self.model.caretime_nurses\n",
    "            curr_info['cum_caretime_doctors'] += self.caretime_doctors\n",
    "            curr_info['cum_caretime_nurses'] += self.caretime_nurses\n",
    "#             self.info.loc[[self.steps+1]]['cum_caretime_doctors'] += curr_info['cum_caretime_doctors']\n",
    "#             self.info.loc[[self.steps+1]]['cum_caretime_nurses'] += curr_info['cum_caretime_nurses']\n",
    "#             curr_info['COUNT_PATIENTS'] = len(self.model.schedule.agents)\n",
    "#             self.info['days_since_admission'] = self.steps\n",
    "            self.NPI = self.model.n_nurses / len(self.model.schedule.agents)\n",
    "            self.careunit = self.info.apply(get_location, axis=1)[0]\n",
    "            self.out_flag = prediction_svm(curr_info,False)[0] #forest.predict(self.info)[0]\n",
    "            # This part is to correct for very short-term releases that occur too often:\n",
    "            if self.out_flag != 0 and self.steps < 4:\n",
    "                draw = np.random.binomial(1,0.5)\n",
    "                if draw==0:\n",
    "                    self.out_flag = 0\n",
    "            \n",
    "            self.steps += 1  # keep track of how many ticks are seen\n",
    "            \n",
    "            #if np.random.binomial(1, 0.1) != 0:  # 10% chance of dying\n",
    "#             if  self.out_flag == 1 or self.out_flag == 2: #  When the patient is discharged/passes away, remove from model\n",
    "#                 self.model.schedule.remove(self)\n",
    "                \n",
    "    def advance(self):\n",
    "        #if  self.out_flag == 1 or self.out_flag == 2: #  When the patient is discharged/passes away, remove from model\n",
    "            #self.model.schedule.remove(self)\n",
    "        if self.out_flag == 2:\n",
    "            self.model.count_discharges +=1\n",
    "            self.model.schedule.remove(self)\n",
    "        if self.out_flag == 1:\n",
    "            self.model.count_deaths +=1\n",
    "            self.model.schedule.remove(self)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "class TestAgentLifespan(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.model = LifeTimeModel()\n",
    "        self.model.run_model()\n",
    "        self.df = self.model.datacollector.get_agent_vars_dataframe()\n",
    "        self.df = self.df.reset_index()\n",
    "\n",
    "    def test_ticks_seen(self):\n",
    "        '''Each agent should be activated no more than one time'''\n",
    "        assert self.df.steps.max() == 1\n",
    "\n",
    "    def test_agent_lifetime(self):\n",
    "        lifetimes = self.df.groupby([\"AgentID\"]).agg(\n",
    "            {\"Step\": lambda x: len(x)})\n",
    "        assert lifetimes.Step.max() == 2\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "model = PatienFlowModel(n_agents=30,max_agents=50,n_doctors=3,n_nurses=300)\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    model.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Results from Model Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>out_flag</th>\n",
       "      <th>days_in_hospital</th>\n",
       "      <th>info</th>\n",
       "      <th>NPI</th>\n",
       "      <th>Careunit</th>\n",
       "      <th>cum_caretime_doctors</th>\n",
       "      <th>cum_caretime_nurses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>AgentID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>age preiculos  gcs heartrate meanbp resp...</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>CSRU</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>7.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>age preiculos  gcs heartrate meanbp resp...</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>MICU</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>7.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>age preiculos  gcs heartrate meanbp resp...</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>MICU</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>7.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>age preiculos  gcs heartrate meanbp resp...</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>SICU</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>7.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>age preiculos  gcs heartrate meanbp resp...</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>CSRU</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>7.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">20</th>\n",
       "      <th>228</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>age preiculos  gcs heartrate meanbp resp...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>MICU</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>age preiculos  gcs heartrate meanbp resp...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>MICU</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>age preiculos  gcs heartrate meanbp resp...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>CSRU</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>age preiculos  gcs heartrate meanbp resp...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>TSICU</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>age preiculos      gcs heartrate  meanbp...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>TSICU</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>784 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              out_flag  days_in_hospital  \\\n",
       "Step AgentID                               \n",
       "1    1               0                 4   \n",
       "     2               2                 3   \n",
       "     3               2                 4   \n",
       "     4               0                 2   \n",
       "     5               0                 4   \n",
       "...                ...               ...   \n",
       "20   228             0                 1   \n",
       "     229             2                 1   \n",
       "     230             1                 1   \n",
       "     231             2                 1   \n",
       "     232             0                 1   \n",
       "\n",
       "                                                           info       NPI  \\\n",
       "Step AgentID                                                                \n",
       "1    1              age preiculos  gcs heartrate meanbp resp...  7.142857   \n",
       "     2              age preiculos  gcs heartrate meanbp resp...  7.142857   \n",
       "     3              age preiculos  gcs heartrate meanbp resp...  7.142857   \n",
       "     4              age preiculos  gcs heartrate meanbp resp...  7.142857   \n",
       "     5              age preiculos  gcs heartrate meanbp resp...  7.142857   \n",
       "...                                                         ...       ...   \n",
       "20   228            age preiculos  gcs heartrate meanbp resp...  6.000000   \n",
       "     229            age preiculos  gcs heartrate meanbp resp...  6.000000   \n",
       "     230            age preiculos  gcs heartrate meanbp resp...  6.000000   \n",
       "     231            age preiculos  gcs heartrate meanbp resp...  6.000000   \n",
       "     232            age preiculos      gcs heartrate  meanbp...  6.000000   \n",
       "\n",
       "             Careunit  cum_caretime_doctors  cum_caretime_nurses  \n",
       "Step AgentID                                                      \n",
       "1    1           CSRU              0.071429             7.142857  \n",
       "     2           MICU              0.071429             7.142857  \n",
       "     3           MICU              0.071429             7.142857  \n",
       "     4           SICU              0.071429             7.142857  \n",
       "     5           CSRU              0.071429             7.142857  \n",
       "...               ...                   ...                  ...  \n",
       "20   228         MICU              0.060000             6.000000  \n",
       "     229         MICU              0.060000             6.000000  \n",
       "     230         CSRU              0.060000             6.000000  \n",
       "     231        TSICU              0.060000             6.000000  \n",
       "     232        TSICU              0.060000             6.000000  \n",
       "\n",
       "[784 rows x 7 columns]"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2 = model.datacollector.get_agent_vars_dataframe()\n",
    "temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_info = pd.DataFrame(temp2.to_records())\n",
    "\n",
    "cum_caretime_doctors = []\n",
    "cum_caretime_nurses = []\n",
    "LOS = []\n",
    "for i in flat_info['AgentID'].unique():\n",
    "    LOS.append(flat_info[flat_info['AgentID']==i]['days_in_hospital'].max())\n",
    "    cum_caretime_doctors.append(flat_info[flat_info['AgentID']==i]['cum_caretime_doctors'].max())\n",
    "    cum_caretime_nurses.append(flat_info[flat_info['AgentID']==i]['cum_caretime_nurses'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_count</th>\n",
       "      <th>max_cap_by</th>\n",
       "      <th>max_cap_daily</th>\n",
       "      <th>count_discharges</th>\n",
       "      <th>count_deaths</th>\n",
       "      <th>demand_serviced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>31</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>46</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>54</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    agent_count  max_cap_by  max_cap_daily  count_discharges  count_deaths  \\\n",
       "0            42           0              0                 0             0   \n",
       "1            39           0              0                13             1   \n",
       "2            38           0              0                23             6   \n",
       "3            34           0              0                33             7   \n",
       "4            34           0              0                39            11   \n",
       "5            38           0              0                44            12   \n",
       "6            38           0              0                52            14   \n",
       "7            37           0              0                57            19   \n",
       "8            42           0              0                62            19   \n",
       "9            43           0              0                71            20   \n",
       "10           41           0              0                77            25   \n",
       "11           38           0              0                84            26   \n",
       "12           40           0              0                89            30   \n",
       "13           40           0              0                98            31   \n",
       "14           36           0              0               103            33   \n",
       "15           36           0              0               105            39   \n",
       "16           35           0              0               112            41   \n",
       "17           37           0              0               115            46   \n",
       "18           46           0              0               121            49   \n",
       "19           50           0              0               128            54   \n",
       "\n",
       "    demand_serviced  \n",
       "0               0.0  \n",
       "1               1.0  \n",
       "2               1.0  \n",
       "3               1.0  \n",
       "4               1.0  \n",
       "5               1.0  \n",
       "6               1.0  \n",
       "7               1.0  \n",
       "8               1.0  \n",
       "9               1.0  \n",
       "10              1.0  \n",
       "11              1.0  \n",
       "12              1.0  \n",
       "13              1.0  \n",
       "14              1.0  \n",
       "15              1.0  \n",
       "16              1.0  \n",
       "17              1.0  \n",
       "18              1.0  \n",
       "19              1.0  "
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp3 = model.datacollector.get_model_vars_dataframe()\n",
    "temp3.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [14:39:02, 1986.60s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "#fixed_params = {\n",
    " #   \"n_agents\": 30,\n",
    "#}\n",
    "parameters = {\"n_doctors\": [2,3], \"max_agents\": [80,100], \"n_nurses\": [150,200,250], \"n_agents\": [30,50,70]}\n",
    "batch_run = BatchRunner(PatienFlowModel, \n",
    "                        parameters,\n",
    "                        #fixed_params,\n",
    "                        iterations=1,\n",
    "                        max_steps=100,\n",
    "                        model_reporters={\"all\":lambda m: m.datacollector})\n",
    "batch_run.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_data = batch_run.get_model_vars_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_data.loc[0,'all'].get_agent_vars_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_data.loc[0,'all'].get_model_vars_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caretime_info = pd.DataFrame(df3[['ICUSTAY_ID','cum_caretime_doctors','cum_caretime_nurses']]\n",
    "                             .groupby('ICUSTAY_ID').max().to_records())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOS_info = df3[['ICUSTAY_ID','LOS']].groupby('ICUSTAY_ID').max()['LOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOS_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,1,1/len(LOS_info)),sorted(round(LOS_info)),color='red')\n",
    "\n",
    "for i in range(run_data.shape[0]):\n",
    "    data = run_data.loc[i,'all'].get_agent_vars_dataframe()\n",
    "    flat_info = pd.DataFrame(data.to_records())\n",
    "    LOS = []\n",
    "    for i in flat_info['AgentID'].unique():\n",
    "        LOS.append(flat_info[flat_info['AgentID']==i]['days_in_hospital'].max())   \n",
    "    plt.plot(np.arange(0,1,1/len(LOS))[:len(LOS)],sorted(LOS),color='blue',alpha=0.3)\n",
    "\n",
    "plt.ylim((0,20))\n",
    "plt.xlabel('Proportion of Patients')\n",
    "plt.ylabel('Length of Stay')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,1,1/len(caretime_info['cum_caretime_doctors'])),\n",
    "         sorted(caretime_info['cum_caretime_doctors']),color='red')\n",
    "\n",
    "\n",
    "for i in range(run_data.shape[0]):\n",
    "    data = run_data.loc[i,'all'].get_agent_vars_dataframe()\n",
    "    flat_info = pd.DataFrame(data.to_records())\n",
    "    cum_caretime_doctors = []\n",
    "    for i in flat_info['AgentID'].unique():\n",
    "        cum_caretime_doctors.append(flat_info[flat_info['AgentID']==i]['cum_caretime_doctors'].max())\n",
    "        \n",
    "    plt.plot(np.arange(0,1,1/len(cum_caretime_doctors))[:len(cum_caretime_doctors)],sorted(cum_caretime_doctors),color='blue',alpha=0.3)\n",
    "\n",
    "plt.ylim((0,1.2))\n",
    "plt.xlim(0,1)\n",
    "plt.xlabel('Proportion of Patients')\n",
    "plt.ylabel('Cumulative Doctor Caretime')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quants = np.arange(0,1,1/len(cum_caretime_nurses)) #1/len(cum_caretime_nurses)\n",
    "plt.plot(np.arange(0,1,1/len(caretime_info['cum_caretime_nurses'])),\n",
    "         sorted(caretime_info['cum_caretime_nurses']),color='red')\n",
    "\n",
    "\n",
    "for i in range(run_data.shape[0]):\n",
    "    data = run_data.loc[i,'all'].get_agent_vars_dataframe()\n",
    "    flat_info = pd.DataFrame(data.to_records())\n",
    "    cum_caretime_nurses = []\n",
    "    for i in flat_info['AgentID'].unique():\n",
    "        cum_caretime_nurses.append(flat_info[flat_info['AgentID']==i]['cum_caretime_nurses'].max())\n",
    "    plt.plot(quants,np.quantile(sorted(cum_caretime_nurses),quants),color='blue',alpha=0.3)\n",
    "\n",
    "plt.ylim((0,125))\n",
    "plt.xlabel('Proportion of Patients')\n",
    "plt.ylabel('Cumulative Nurse Caretime')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mortality_LOS_info = pd.DataFrame(df3[['ICUSTAY_ID','HOSPITAL_EXPIRE_FLAG','LOS']]\n",
    "                             .groupby('ICUSTAY_ID').max().to_records())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting LOS only of those cases where patients passes away\n",
    "mortality_LOS_info2 = mortality_LOS_info[mortality_LOS_info['HOSPITAL_EXPIRE_FLAG']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,1,1/len(mortality_LOS_info2['LOS'])),\n",
    "         sorted(round(mortality_LOS_info2['LOS'])),color='red',label=\"Actual All\",alpha=0.3)\n",
    "\n",
    "for i in range(run_data.shape[0]):\n",
    "    data = run_data.loc[i,'all'].get_agent_vars_dataframe()\n",
    "    flat_info = pd.DataFrame(data.to_records())\n",
    "    flat_info2 = flat_info[flat_info['out_flag']==2] # Fatalities\n",
    "    LOS = []\n",
    "    for i in flat_info2['AgentID'].unique():\n",
    "        LOS.append(flat_info2[flat_info2['AgentID']==i]['days_in_hospital'].max())   \n",
    "    plt.plot(np.arange(0,1,1/len(LOS))[:len(LOS)],sorted(LOS),color='blue',alpha=0.3)\n",
    "    #plt.plot(np.arange(0,1,1/len(flat_info2.days_in_hospital)),sorted(round(flat_info2.days_in_hospital)),color='blue',label=\"ABM ALL\",alpha=0.3)\n",
    "\n",
    "plt.ylim((0,20))\n",
    "plt.xlabel('Proportion of Patients')\n",
    "plt.ylabel('Length of Stay (of Fatalities)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_info2 = flat_info[flat_info['out_flag']==2] # Fatalities\n",
    "flat_info3 = flat_info[flat_info['out_flag']==1] # Discharge\n",
    "\n",
    "plt.style.use('seaborn-deep')\n",
    "x = flat_info2.days_in_hospital\n",
    "y = flat_info3.days_in_hospital\n",
    "x_w = np.empty(x.shape)\n",
    "x_w.fill(1/x.shape[0])\n",
    "y_w = np.empty(y.shape)\n",
    "y_w.fill(1/y.shape[0])\n",
    "bins = np.linspace(0, 50, 30)\n",
    "\n",
    "plt.hist([x, y], bins,weights=[x_w, y_w], label=['Mortalities', 'Discharges'])\n",
    "plt.xlim((0,30))\n",
    "#plt.ylim((0,0.95))\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Length of Stay')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoomed In for better Analysis\n",
    "plt.hist([x, y], bins,weights=[x_w, y_w], label=['Mortalities', 'Discharges'])\n",
    "plt.xlim((0,30))\n",
    "plt.ylim((0,0.90))\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Length of Stay')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_count = []\n",
    "for i in flat_info['Step'].unique():\n",
    "    unit_count.append(flat_info[flat_info['Step']==i]['Careunit'].value_counts().to_dict())\n",
    "\n",
    "unit_count = pd.DataFrame(unit_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(unit_count['MICU'],label = \"MICU\")\n",
    "plt.plot(unit_count['SICU'],label = \"SICU\")\n",
    "plt.plot(unit_count['CSRU'], label = \"CSRU\")\n",
    "plt.plot(unit_count['TSICU'], label = \"TSICU\")\n",
    "plt.xlabel('Days of Simulation')\n",
    "plt.ylabel('Number of beds occupied')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "        return (x - x.min(0)) / x.ptp(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(count_LOS).hist(bins=32, normed=True,grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_info['info'][0]#[1]\n",
    "#flat_info['info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_info[flat_info['out_flag']==1][:50] # Fatalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "import seaborn as sns\n",
    "# Reference Data:\n",
    "fatal_df=df6[df6[\"HOSPITAL_EXPIRE_FLAG\"]==1] # Fatalities\n",
    "\n",
    "#ABM Data:\n",
    "count_deaths_series =[]\n",
    "for i in range(run_data.shape[0]):\n",
    "    data = run_data.loc[i,'all'].get_agent_vars_dataframe()\n",
    "    flat_info = pd.DataFrame(data.to_records())\n",
    "    flat_info2 = flat_info[flat_info['out_flag']==1] # Fatalities\n",
    "    count_LOS =[]\n",
    "    #for j in range(0,len(flat_info2)):\n",
    "        #count_LOS.append(list(flat_info2.days_in_hospital)[j])\n",
    "    for i in flat_info2['AgentID'].unique():\n",
    "        count_LOS.append(flat_info2[flat_info2['AgentID']==i]['days_in_hospital'].max()) \n",
    "    sns.kdeplot(count_LOS, bw=.6, label=\"bw: 0.6\",color='grey')\n",
    "    #sns.distplot(count_LOS,hist = False, kde = True,\n",
    "    #             kde_kws = {'shade': True, 'linewidth': 1},color='grey',label='ABM Simulation')\n",
    "sns.kdeplot(round(fatal_df[\"LOS\"]), bw=.6, label=\"bw: 0.6\",color='blue')\n",
    "#sns.distplot(round(fatal_df[\"LOS\"]),hist = False, kde = True,\n",
    "   #         kde_kws = {'shade': True, 'linewidth': 1},color='blue',label='Actual Data')\n",
    "\n",
    "#plt.xlim((30,50))\n",
    "#plt.ylim((0.8,1))\n",
    "plt.title('Density Plot with Multiple Simulations')\n",
    "plt.xlabel('LOS(days) of patients who passed away')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVERYTHING BEYOND HERE IS NOT NECESSARY FOR MY ANALYSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Intervals for Discharges and Deaths [DELETE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TAKES A LONG TIME TO RUN!!\n",
    "\n",
    "# --------\n",
    "\n",
    "#n = 30 # number of iterations of model run\n",
    "#discharges_all =[]\n",
    "#deaths_all =[]\n",
    "#for j in range(n):\n",
    "    #Run the model\n",
    "#    model = PatienFlowModel(n_agents=20)\n",
    "#    for i in range(50):\n",
    "#        model.step()\n",
    "#    temp4 = model.datacollector.get_model_vars_dataframe()\n",
    "#    count_discharges= [temp4[\"count_discharges\"]]\n",
    "#    count_deaths = [temp4[\"count_deaths\"]]\n",
    "#    discharges_all.append(count_discharges)\n",
    " #   deaths_all.append(count_deaths)\n",
    "    \n",
    "#Create a dataframe of all runs and plot simulations\n",
    "#df_overall = pd.DataFrame()\n",
    "#for i in range(0,len(discharges_all)):\n",
    "#    df_temp = pd.DataFrame(discharges_all[i]).T\n",
    "#    df_overall= pd.concat([df_overall,df_temp],axis=1)\n",
    "\n",
    "#plt.plot(df_overall,alpha=0.3)\n",
    "#plt.show()\n",
    "\n",
    "#df_overall2 = pd.DataFrame()\n",
    "#for i in range(0,len(deaths_all)):\n",
    "#    df_temp2 = pd.DataFrame(deaths_all[i]).T\n",
    "#    df_overall2= pd.concat([df_overall2,df_temp2],axis=1)\n",
    "\n",
    "#plt.plot(df_overall2,alpha=0.3)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily-Exceeding Capacity [UPDATE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a max_capacity in the ICU which has been defined in the model this plot can be used to figure out the point in time, where new **patients** can not be admitted to the ICU anymore and **need to be transfered to another hospital**. The basic model assumes a 100% service level for capacity, however further below a batch-model is presented, where for different service levels the same information can be retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count = 0\n",
    "#for i in temp3[\"max_cap_daily\"]:\n",
    "#    if i!=0:\n",
    "#        count +=1\n",
    "#print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = sum(temp3[\"max_cap_daily\"])/len(temp3[\"max_cap_daily\"])\n",
    "plt.plot(temp3.index,temp3[\"max_cap_daily\"], label = \"Daily Exceeding\")\n",
    "plt.plot(temp3.index,[avg for i in range(0,len(temp3))], label = \"Average\")\n",
    "plt.plot(temp3.index,temp3[\"new_patients_demand\"], label = \"Patient Inflow (Demand)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nurse-Patient-Interaction [DELETE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the Sum of All Nurse to Patient interaction ratios (proxy for interaction time)\n",
    "NPI = []\n",
    "for i in flat_info['AgentID'].unique():\n",
    "    NPI.append(flat_info[flat_info['AgentID']==i]['NPI'].sum())\n",
    "\n",
    "NPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is supposed to show that the higher the sum of NPI ratios (x-axis), the higher the LOS\n",
    "plt.scatter(NPI,LOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Careunit Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_info = pd.DataFrame(temp2.to_records())\n",
    "\n",
    "unit_count = []\n",
    "for i in flat_info['Step'].unique():\n",
    "    unit_count.append(flat_info[flat_info['Step']==i]['Careunit'].value_counts().to_dict())\n",
    "\n",
    "unit_count = pd.DataFrame(unit_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(unit_count['MICU'],label = \"MICU\")\n",
    "plt.plot(unit_count['SICU'],label = \"SICU\")\n",
    "plt.plot(unit_count['CSRU'], label = \"CSRU\")\n",
    "plt.plot(unit_count['TSICU'], label = \"TSICU\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fatalities per Day (Absolute and Percentage) [DELETE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_info = pd.DataFrame(temp2.to_records())\n",
    "\n",
    "unit_count = []\n",
    "for i in flat_info['Step'].unique():\n",
    "    unit_count.append(flat_info[flat_info['Step']==i]['out_flag'].value_counts().to_dict())\n",
    "\n",
    "unit_count\n",
    "unit_count = pd.DataFrame(unit_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(unit_count[0],label = \"Count_Stays\")\n",
    "#plt.plot(unit_count[1],label = \"Count_Discharges\")\n",
    "plt.plot(unit_count[2], label = \"Count_Fatalities\") #There are currently no death predictions\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vital Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flat_info[\"info\"][0][\"heartrate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flat_info[\"info\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flat_info = pd.DataFrame(temp2.to_records())\n",
    "\n",
    "#vital_A = []\n",
    "#for i in flat_info['AgentID'].unique():\n",
    " #   vital_A.append(flat_info[\"info\"][0][flat_info['AgentID']==3][\"heartrate\"])\n",
    "\n",
    "#vital_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model  Results from Model Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Agents in the Model per Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think this does 100 steps for each agent --> range(20)\n",
    "#for j in range(100):\n",
    "    # Run the model\n",
    "#    model = PatienFlowModel(n_agents=20)\n",
    "#    for i in range(20):\n",
    "#        model.step()\n",
    "        \n",
    "#model_df = model.datacollector.get_model_vars_dataframe()\n",
    "#n_agents = [model_df[\"agent_count\"]]\n",
    "#n_agents = [a.unique_id for a in model.schedule.agents]\n",
    "#plt.hist(n_agents,bins=10)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing Capacity Excess (max_cap_by)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Runner for different service levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fixed_params = {\n",
    "    \"max_agents\": 100,\n",
    "}\n",
    "parameters = {\"service_level\": [0.75 , 0.8 , 0.85 , 0.9 , 0.95 , 1]}\n",
    "batch_run = BatchRunner(PatienFlowModel, \n",
    "                        parameters,\n",
    "                        fixed_params,\n",
    "                        iterations=2,\n",
    "                        max_steps=80,\n",
    "                        model_reporters={\"max_cap_by\":lambda m: m.max_cap_by})\n",
    "batch_run.run_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Runner for different number of agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fixed_params = {\n",
    "    \"max_agents\": 100,\n",
    "}\n",
    "parameters = {\"n_agents\": range(10, 100, 5)}\n",
    "batch_run = BatchRunner(PatienFlowModel, \n",
    "                        parameters,\n",
    "                        fixed_params,\n",
    "                        iterations=5,\n",
    "                        max_steps=100,\n",
    "                        model_reporters={\"max_cap_by\":lambda m: m.max_cap_by})\n",
    "batch_run.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_data = batch_run.get_model_vars_dataframe()\n",
    "#run_data.head()\n",
    "plt.scatter(run_data.n_agents, run_data.max_cap_by)\n",
    "plt.xlabel('n_agents', fontsize=15)\n",
    "plt.ylabel('Capacity Excess', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection  import ParameterGrid\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# set seed\n",
    "SEED=3642\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def get_models():\n",
    "    #Generate a library of simple learners\n",
    "    #svr = SVR(C=1, gamma= 0.25)\n",
    "    #knn = KNeighborsRegressor(n_neighbors=5)\n",
    "    lr = LogisticRegression(C=100, random_state=SEED, solver='newton-cg', max_iter=1000)\n",
    "    #rf = RandomForestRegressor(n_estimators=30, max_features=10, random_state=SEED)\n",
    "    gb = xgb.XGBClassifier(base_score=0.5, booster='gbtree',\n",
    "                                     colsample_bylevel=1, colsample_bynode=1,\n",
    "                                     colsample_bytree=1, gamma=0,\n",
    "                                     learning_rate=0.1, max_delta_step=0,\n",
    "                                     max_depth=3, min_child_weight=1,\n",
    "                                     missing=None, n_estimators=100, n_jobs=1,\n",
    "                                     nthread=None, objective='binary:logistic',\n",
    "                                     random_state=0, reg_alpha=0,\n",
    "                                     scale_pos_weight=1, seed=None, silent=None,\n",
    "                                     subsample=1, verbosity=1)\n",
    "    \n",
    "    #gb = xgb.XGBRegressor(colsample_bytree= 0.7, \n",
    "                            #learning_rate= 0.07, \n",
    "                          #max_depth= 7, \n",
    "                         # min_child_weight= 4,\n",
    "                          #n_estimators= 90, \n",
    "                          #nthread= 3, \n",
    "                          #objective= 'reg:linear', \n",
    "                         # silent= 1, \n",
    "                          #subsample= 0.7)\n",
    "\n",
    "    models = {#'svm': svr,\n",
    "              #'knn': knn,\n",
    "              #'random forest': rf,\n",
    "              #'logistic': lr,\n",
    "              'Xboost Classifier': gb\n",
    "              }\n",
    "\n",
    "    return models\n",
    "\n",
    "\n",
    "def train_predict(model_list,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test):\n",
    "    #Fit models in list on training set and return preds\n",
    "    P = np.zeros((y_test.shape[0], len(model_list)))\n",
    "    P = pd.DataFrame(P)\n",
    "\n",
    "    cols = list()\n",
    "    for i, (name, m) in enumerate(models.items()):\n",
    "        print(\"%s...\" % name, end=\" \", flush=False)\n",
    "        m.fit(X_train, y_train)\n",
    "        P.iloc[:, i] = m.predict_proba(X_test)[:, 1]\n",
    "        #P.iloc[:, i] = m.predict(X_test)\n",
    "        cols.append(name)\n",
    "        print(\"done\")\n",
    "\n",
    "    P.columns = cols\n",
    "    print(\"Done.\\n\")\n",
    "    return P\n",
    "\n",
    "\n",
    "def score_models(P, y):\n",
    "     # Score model in test set\n",
    "    print(\"Scoring models.\")\n",
    "    #mse_scores=[]\n",
    "    #r2_scores=[]\n",
    "    auc_score=[]\n",
    "    \n",
    "    for m in P.columns:\n",
    "        #score = mean_squared_error(y, P.loc[:, m])\n",
    "        score = get_auc(y_test,  P.iloc[:, m],[0,1],column=1, plot=False)\n",
    "        auc_scores.append(score)\n",
    "        r2_score_temp = r2_score(y, P.loc[:, m])\n",
    "        r2_scores.append(r2_score_temp)\n",
    "        print(\"%-26s: MSE: %.3f R^2: %.3f\" %(m, score, r2_score_temp))\n",
    "    return P.columns, auc_scores, r2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_fit = xgb.XGBClassifier(base_score=0.5, booster='gbtree',\n",
    "                                     colsample_bylevel=1, colsample_bynode=1,\n",
    "                                     colsample_bytree=0.8, gamma=0,\n",
    "                                     learning_rate=0.1, max_delta_step=0,\n",
    "                                     max_depth=5, min_child_weight=1,\n",
    "                                     missing=None, n_estimators=140, n_jobs=1,\n",
    "                                     nthread=4, objective='binary:logistic',\n",
    "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
    "                                     scale_pos_weight=1, seed=27, silent=None,\n",
    "                                     subsample=0.8, verbosity=1).fit(X_train,y_train)\n",
    "get_auc(y_test, gb_fit.predict_proba(X_test),[0,1], column=1, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_models()\n",
    "P = train_predict(models,X_train,y_train,X_test,y_test)\n",
    "my_models, auc_scores, r2_scores= score_models(P, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "MyXGB = xgb.XGBClassifier() #objective='reg:squarederror'\n",
    "parameters = {'nthread':[3], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "              'max_depth': [5, 6, 7],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [90]}\n",
    "\n",
    "grid_knn_acc = GridSearchCV(MyXGB, param_grid = parameters, scoring = 'r2', cv=5, refit=True,n_jobs=3)\n",
    "grid_knn_acc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier(learning_rate =0.1, n_estimators=140, \n",
    "                                                  max_depth=5,min_child_weight=1, gamma=0, subsample=0.8, \n",
    "                                                  colsample_bytree=0.8, objective= 'binary:logistic', nthread=4, \n",
    "                                                  scale_pos_weight=1,seed=27), param_grid = param_test1, \n",
    "                                                  scoring='roc_auc',n_jobs=2,cv=5)\n",
    "gsearch1.fit(X_train,y_train)\n",
    "#gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df2 = pd.read_csv('main_df2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(main_df2[\"SEQ_NUM\"],bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "244px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
